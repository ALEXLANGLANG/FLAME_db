{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p should be larger than 2\n",
      "Insert 1000 rows successfully to Database\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flame_db.gen_insert_data import *\n",
    "from flame_db.FLAME_db_algorithm import *\n",
    "from flame_db.matching_helpers import *\n",
    "from flame_db.utils import *\n",
    "import unittest\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_statistics(res_post_new):\n",
    "    ATE_ = ATE_db(res_post_new)\n",
    "    ATT_ = ATT_db(res_post_new)\n",
    "    if type(ATE_) == np.nan:\n",
    "        print(\"ATE: \" + str(ATE_))\n",
    "        return True\n",
    "    if type(ATT_) == np.nan:\n",
    "        print(\"ATT:\" + str(ATT_))\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "p = 20\n",
    "TE = 5\n",
    "gen_data_db(n = 100,p = 2, TE = TE)\n",
    "data,weight_array = gen_data_db(n = 1000,p = p, TE = TE)\n",
    "holdout,weight_array = gen_data_db(n = 500,p = p, TE = TE)\n",
    "#Connect to the database\n",
    "select_db = \"MySQL\"  # Select the database you are using\n",
    "database_name='tmp' # database name\n",
    "host ='vcm-17819.vm.duke.edu' # \"127.0.0.1\"\n",
    "port = \"5432\"\n",
    "user=\"newuser\"\n",
    "password= \"sunxian123\"\n",
    "conn = connect_db(database_name, user, password, host, port)\n",
    "#Insert the data into database\n",
    "# insert_data_to_db(\"test_df100\", # The name of your table containing the dataset to be matched\n",
    "#                     data,\n",
    "#                     treatment_column_name= \"treated\",\n",
    "#                     outcome_column_name= 'outcome',conn = conn)\n",
    "insert_data_to_db(\"test_df101\", # The name of your table containing the dataset to be matched\n",
    "                    data,\n",
    "                    treatment_column_name= \"treated\",\n",
    "                    outcome_column_name= 'outcome',conn = conn)\n",
    "\n",
    "# holdout_path = os.path.join((os.path.dirname(__file__)), 'holdout.csv')\n",
    "\n",
    "# class TestFlame_db(unittest.TestCase):\n",
    "              \n",
    "#     def test_weights(self):\n",
    "#         is_corrct = 1\n",
    "#         try:\n",
    "#             res_post_new1 = FLAME_db(input_data = \"test_df100\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     treatment_column_name= \"treated\",\n",
    "#                                     outcome_column_name= 'outcome',\n",
    "#                                     adaptive_weights = 'ridge',\n",
    "#                                     C = 0.1,\n",
    "#                                     conn = conn,\n",
    "#                                     matching_option = 0,\n",
    "#                                     verbose = 3,\n",
    "#                                     k = 0\n",
    "#                                     )\n",
    "#             holdout_path = os.path.join((os.path.dirname(__file__)), 'holdout.csv')\n",
    "            \n",
    "#             res_post_new1 = FLAME_db(input_data = \"test_df101\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout_path, # holdout set\n",
    "#                                     treatment_column_name= \"treated\",\n",
    "#                                     outcome_column_name= 'outcome',\n",
    "#                                     C = 0.1,\n",
    "#                                     conn = conn,\n",
    "#                                     matching_option = 0,\n",
    "#                                     verbose = 3,\n",
    "#                                     k = 0\n",
    "#                                     )\n",
    "# #            res_post_new2 = FLAME_db(input_data = \"test_df100\", # The name of your table containing the dataset to be matched\n",
    "#                                    holdout_data = holdout, # holdout set\n",
    "#                                    treatment_column_name= \"treated\",\n",
    "#                                    outcome_column_name= 'outcome',\n",
    "#                                    C = 0.1,\n",
    "#                                    conn = conn,\n",
    "#                                    matching_option = 2,\n",
    "#                                    adaptive_weights = False,\n",
    "#                                    weight_array = weight_array,\n",
    "#                                    verbose = 3,\n",
    "#                                    k = 0\n",
    "#                                    )\n",
    "#             if check_statistics(res_post_new1):  #or check_statistics(res_post_new2):\n",
    "#                 is_corrct = 0\n",
    "            \n",
    "#         except (KeyError, ValueError):\n",
    "#                 is_corrct = 0\n",
    "\n",
    "#         self.assertEqual(1, is_corrct,\n",
    "#                              msg='Error when test weights')\n",
    "\n",
    "\n",
    "#    def test_missing_datasets(self):\n",
    "#        is_corrct = 1\n",
    "#        try:\n",
    "#\n",
    "#            holdout_miss = holdout.copy()\n",
    "#            m,n = holdout_miss.shape\n",
    "#            for i in range(int(m/100)):\n",
    "#                for j in [0,int(n/2)]:\n",
    "#                    holdout_miss.iloc[i,j] = np.nan\n",
    "#            res_post_new = FLAME_db(input_data = \"test_df100\", # The name of your table containing the dataset to be matched\n",
    "#                                    holdout_data = holdout_miss, # holdout set\n",
    "#                                    C = 0,\n",
    "#                                    conn = conn,\n",
    "#                                    matching_option = 2,\n",
    "#                                    adaptive_weights = 'decisiontree',\n",
    "#                                    verbose = 1,\n",
    "#                                    missing_data_replace = 0,\n",
    "#                                    missing_holdout_replace = 0)\n",
    "#            if check_statistics(res_post_new):\n",
    "#                is_corrct = 0\n",
    "#\n",
    "#        except (KeyError, ValueError):\n",
    "#                is_corrct = 0\n",
    "#\n",
    "#        self.assertEqual(1, is_corrct,\n",
    "#                             msg='Error when test missing datasets')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p should be larger than 2\n"
     ]
    }
   ],
   "source": [
    "p = 20\n",
    "TE = 5\n",
    "gen_data_db(n = 100,p = 2, TE = TE)\n",
    "data,weight_array = gen_data_db(n = 1000,p = p, TE = TE)\n",
    "holdout,weight_array = gen_data_db(n = 500,p = p, TE = TE)\n",
    "holdout.to_csv(\"holdout.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cov1</th>\n",
       "      <th>cov2</th>\n",
       "      <th>cov3</th>\n",
       "      <th>cov4</th>\n",
       "      <th>cov5</th>\n",
       "      <th>cov6</th>\n",
       "      <th>cov7</th>\n",
       "      <th>cov8</th>\n",
       "      <th>cov9</th>\n",
       "      <th>cov10</th>\n",
       "      <th>...</th>\n",
       "      <th>cov13</th>\n",
       "      <th>cov14</th>\n",
       "      <th>cov15</th>\n",
       "      <th>cov16</th>\n",
       "      <th>cov17</th>\n",
       "      <th>cov18</th>\n",
       "      <th>cov19</th>\n",
       "      <th>cov20</th>\n",
       "      <th>treated</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115.317473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.575213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>208.753384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.639861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.891596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.456484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.615869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.382697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.163829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.221086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cov1  cov2  cov3  cov4  cov5  cov6  cov7  cov8  cov9 cov10  ... cov13  \\\n",
       "0    Good  Good  Good   Bad   Bad   Bad  Good   Bad  Good   Bad  ...   Bad   \n",
       "1     Bad   Bad   Bad   Bad  Good  Good   Bad   Bad  Good   Bad  ...  Good   \n",
       "2     Bad   Bad  Good   Bad  Good   Bad  Good  Good  Good  Good  ...  Good   \n",
       "3     Bad  Good  Good  Good   Bad   Bad   Bad   Bad  Good   Bad  ...   Bad   \n",
       "4    Good   Bad   Bad  Good   Bad   Bad   Bad  Good   Bad   Bad  ...  Good   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "495  Good   Bad  Good  Good   Bad  Good  Good   Bad   Bad   Bad  ...   Bad   \n",
       "496   Bad   Bad   Bad  Good   Bad  Good   Bad  Good  Good  Good  ...  Good   \n",
       "497  Good   Bad   Bad  Good   Bad  Good   Bad   Bad  Good   Bad  ...  Good   \n",
       "498  Good   Bad   Bad   Bad  Good   Bad  Good  Good  Good   Bad  ...  Good   \n",
       "499  Good   Bad   Bad   Bad   Bad   Bad  Good   Bad   Bad  Good  ...   Bad   \n",
       "\n",
       "    cov14 cov15 cov16 cov17 cov18 cov19 cov20 treated     outcome  \n",
       "0     Bad  Good  Good  Good  Good   Bad   0.0     1.0  115.317473  \n",
       "1     Bad  Good  Good  Good  Good   Bad   0.0     0.0  100.575213  \n",
       "2     Bad  Good  Good   Bad  Good  Good   0.0     0.0  208.753384  \n",
       "3    Good   Bad   Bad  Good   Bad  Good   0.0     1.0   96.639861  \n",
       "4    Good  Good  Good   Bad  Good   Bad   0.0     0.0   64.891596  \n",
       "..    ...   ...   ...   ...   ...   ...   ...     ...         ...  \n",
       "495  Good  Good   Bad  Good   Bad  Good   0.0     1.0  110.456484  \n",
       "496  Good   Bad   Bad  Good  Good  Good   0.0     0.0  185.615869  \n",
       "497   Bad   Bad  Good  Good  Good   Bad   0.0     1.0  103.382697  \n",
       "498  Good   Bad  Good  Good   Bad   Bad   1.0     0.0  150.163829  \n",
       "499   Bad   Bad  Good   Bad   Bad  Good   0.0     0.0   91.221086  \n",
       "\n",
       "[500 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"holdout.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File holdout.csv does not exist: 'holdout.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7c3d8404fb1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mholdout_path\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'holdout.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m res_post_new1 = FLAME_db(input_data = \"test_df101\", # The name of your table containing the dataset to be matched\n\u001b[0m\u001b[1;32m      3\u001b[0m                         \u001b[0mholdout_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mholdout_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# holdout set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mtreatment_column_name\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"treated\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0moutcome_column_name\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'outcome'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/github/ALex/FLAME_db/flame_db/FLAME_db_algorithm.py\u001b[0m in \u001b[0;36mFLAME_db\u001b[0;34m(input_data, holdout_data, conn, treatment_column_name, outcome_column_name, weight_array, adaptive_weights, alpha, max_depth, random_state, early_stop_iterations, early_stop_un_c_frac, early_stop_un_t_frac, early_stop_pe_frac, early_stop_pe, C, k, ratio, matching_option, verbose, missing_data_replace, missing_holdout_replace)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;31m#Read file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0mholdout_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mholdout_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;31m# Check if  input in the database and holdout have legal data type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     check_parameters(holdout_data,adaptive_weights,weight_array,C, k, ratio, matching_option,verbose,alpha, max_depth,\n",
      "\u001b[0;32m~/Desktop/github/ALex/FLAME_db/flame_db/checker.py\u001b[0m in \u001b[0;36mread_files\u001b[0;34m(input_data, holdout_data)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mdf_holdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mholdout_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mdf_holdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File holdout.csv does not exist: 'holdout.csv'"
     ]
    }
   ],
   "source": [
    "holdout_path ='holdout.csv'\n",
    "res_post_new1 = FLAME_db(input_data = \"test_df101\", # The name of your table containing the dataset to be matched\n",
    "                        holdout_data = holdout_path, # holdout set\n",
    "                        treatment_column_name= \"treated\",\n",
    "                        outcome_column_name= 'outcome',\n",
    "                        C = 0.1,\n",
    "                        conn = conn,\n",
    "                        matching_option = 0,\n",
    "                        verbose = 3,\n",
    "                        k = 0\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from flame_db.gen_insert_data import *\n",
    "# from flame_db.FLAME_db_algorithm import *\n",
    "# from flame_db.matching_helpers import *\n",
    "# from flame_db.utils import *\n",
    "# import unittest\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def check_statistics(res_post_new):\n",
    "#     ATE_ = ATE_db(res_post_new)\n",
    "#     ATT_ = ATT_db(res_post_new)\n",
    "#     if type(ATE_) == np.nan:\n",
    "#         print(\"ATE: \" + str(ATE_))\n",
    "#         return True\n",
    "#     if type(ATT_) == np.nan:\n",
    "#         print(\"ATT:\" + str(ATT_))\n",
    "#         return True\n",
    "#     return False\n",
    "\n",
    "\n",
    "# p = 20\n",
    "# TE = 5\n",
    "# gen_data_db(n = 1000,p = 2, TE = TE)\n",
    "# data,weight_array = gen_data_db(n = 1000,p = p, TE = TE)\n",
    "# holdout,weight_array = gen_data_db(n = 500,p = p, TE = TE)\n",
    "# #Connect to the database\n",
    "# select_db = \"postgreSQL\"  # Select the database you are using\n",
    "# database_name='tmp' # database name\n",
    "# host ='vcm-17819.vm.duke.edu' # \"127.0.0.1\"\n",
    "# port = \"5432\"\n",
    "# user=\"newuser\"\n",
    "# password= \"sunxian123\"\n",
    "# conn = connect_db(database_name, user, password, host, port)\n",
    "# #Insert the data into database\n",
    "# insert_data_to_db(\"test_df100\", # The name of your table containing the dataset to be matched\n",
    "#                     data,\n",
    "#                     treatment_column_name= \"treated\",\n",
    "#                     outcome_column_name= 'outcome',conn = conn)\n",
    "\n",
    "# res_post_new1 = FLAME_db(input_data = \"test_df100\", # The name of your table containing the dataset to be matched\n",
    "#                         holdout_data = holdout, # holdout set\n",
    "#                         treatment_column_name= \"treated\",\n",
    "#                         outcome_column_name= 'outcome',\n",
    "#                         C = 0.1,\n",
    "#                         conn = conn,\n",
    "#                         matching_option = 0,\n",
    "#                         verbose = 3,\n",
    "#                         k = 0\n",
    "#                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.loc[:,'treated'] ==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_post_new1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from flame_db.gen_insert_data import *\n",
    "# from flame_db.FLAME_db_algorithm import *\n",
    "# from flame_db.matching_helpers import *\n",
    "# from flame_db.utils import *\n",
    "# import unittest\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def check_statistics(res_post_new):\n",
    "#     ATE_ = ATE_db(res_post_new)\n",
    "#     ATT_ = ATT_db(res_post_new)\n",
    "#     if type(ATE_) == np.nan:\n",
    "#         print(\"ATE: \" + str(ATE_))\n",
    "#         return True\n",
    "#     if type(ATT_) == np.nan:\n",
    "#         print(\"ATT:\" + str(ATT_))\n",
    "#         return True\n",
    "#     return False\n",
    "\n",
    "\n",
    "# p = 20\n",
    "# TE = 5\n",
    "# gen_data_db(n = 1000,p = 2, TE = TE)\n",
    "# data,weight_array = gen_data_db(n = 1000,p = p, TE = TE)\n",
    "# holdout,weight_array = gen_data_db(n = 500,p = p, TE = TE)\n",
    "# #Connect to the database\n",
    "# select_db = \"postgreSQL\"  # Select the database you are using\n",
    "# database_name='tmp' # database name\n",
    "# host ='vcm-17819.vm.duke.edu' # \"127.0.0.1\"\n",
    "# port = \"5432\"\n",
    "# user=\"newuser\"\n",
    "# password= \"sunxian123\"\n",
    "# conn = connect_db(database_name, user, password, host, port)\n",
    "\n",
    "# class TestFlame_db(unittest.TestCase):\n",
    "              \n",
    "#     def test_weights(self):\n",
    "#         is_corrct = 1\n",
    "#         try:\n",
    "            \n",
    "#             #Insert the data into database\n",
    "#             insert_data_to_db(\"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                 data,\n",
    "#                                 treatment_column_name= \"treated\",\n",
    "#                                 outcome_column_name= 'outcome',conn = conn)\n",
    "#             res_post_new1 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     treatment_column_name= \"treated\",\n",
    "#                                     outcome_column_name= 'outcome',\n",
    "#                                     C = 0.1,\n",
    "#                                     conn = conn,\n",
    "#                                     matching_option = 0,\n",
    "#                                     verbose = 3,\n",
    "#                                     k = 0\n",
    "#                                     )\n",
    "#             res_post_new2 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     treatment_column_name= \"treated\",\n",
    "#                                     outcome_column_name= 'outcome',\n",
    "#                                     C = 0.1,\n",
    "#                                     conn = conn,\n",
    "#                                     matching_option = 2,\n",
    "#                                     adaptive_weights = False,\n",
    "#                                     weight_array = weight_array,\n",
    "#                                     verbose = 3,\n",
    "#                                     k = 0\n",
    "#                                     )\n",
    "#             if check_statistics(res_post_new1) or check_statistics(res_post_new2):\n",
    "#                 is_corrct = 0\n",
    "            \n",
    "#         except (KeyError, ValueError):\n",
    "#                 is_corrct = 0\n",
    "\n",
    "#         self.assertEqual(1, is_corrct,\n",
    "#                              msg='Error when test weights')\n",
    "\n",
    "\n",
    "#     def test_missing_datasets(self):\n",
    "#         is_corrct = 1\n",
    "#         try:\n",
    "#             holdout_miss = holdout.copy()\n",
    "#             m,n = holdout_miss.shape\n",
    "#             for i in range(int(m/100)):\n",
    "#                 for j in [0,int(n/2)]:\n",
    "#                     holdout_miss.iloc[i,j] = np.nan\n",
    "#             res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout_miss, # holdout set\n",
    "#                                     C = 0,\n",
    "#                                     conn = conn,\n",
    "#                                     matching_option = 2,\n",
    "#                                     adaptive_weights = 'decisiontree',\n",
    "#                                     verbose = 1,\n",
    "#                                     missing_data_replace = 0,\n",
    "#                                     missing_holdout_replace = 0)\n",
    "#             if check_statistics(res_post_new):\n",
    "#                 is_corrct = 0\n",
    "\n",
    "#         except (KeyError, ValueError):\n",
    "#                 is_corrct = 0\n",
    "\n",
    "#         self.assertEqual(1, is_corrct,\n",
    "#                              msg='Error when test missing datasets')  \n",
    "\n",
    "\n",
    "# class Test_exceptions(unittest.TestCase):\n",
    "    \n",
    "#     def test_false_dataset(self):\n",
    "#         def broken_false_dataset():\n",
    "#             res_post_new1 = FLAME_db(input_data = data, # The name of your table containing the dataset to be matched\n",
    "#                                                 holdout_data = holdout, # holdout set\n",
    "#                                                 C = 0.1,\n",
    "#                                                 conn = conn,\n",
    "#                                                 matching_option = 0,\n",
    "#                                                 verbose = 3,\n",
    "#                                                 k = 0\n",
    "#                                                 )\n",
    "#         with self.assertRaises(Exception) as false_dataset:\n",
    "#             broken_false_dataset()\n",
    "            \n",
    "#         self.assertTrue(\"Need to specify the name of the table that contains the dataset in your database \"\\\n",
    "#                         \"frame in parameter 'input_data'\" in str(false_dataset.exception))\n",
    "        \n",
    "#     def test_false_holdout(self):\n",
    "#         def broken_false_holdout():\n",
    "#             res_post_new1 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                                 holdout_data = 0, # holdout set\n",
    "#                                                 C = 0.1,\n",
    "#                                                 conn = conn,\n",
    "#                                                 matching_option = 0,\n",
    "#                                                 verbose = 3,\n",
    "#                                                 k = 0\n",
    "#                                                 )\n",
    "#         with self.assertRaises(Exception) as holdout:\n",
    "#             broken_false_holdout()\n",
    "            \n",
    "#         self.assertTrue(\"Holdout_data shoule be a dataframe or a directory\" in str(holdout.exception))\n",
    "\n",
    "        \n",
    "#     def test_false_treatment_column_name(self):\n",
    "#         def broken_treatment_column_name():\n",
    "#             res_post_new1 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                                 holdout_data = holdout, # holdout set\n",
    "#                                                 treatment_column_name= \"sadfdag\",\n",
    "#                                                 C = 0.1,\n",
    "#                                                 conn = conn,\n",
    "#                                                 matching_option = 0,\n",
    "#                                                 verbose = 3,\n",
    "#                                                 k = 0\n",
    "#                                                 )\n",
    "#         with self.assertRaises(Exception) as treatment_column_name:\n",
    "#             broken_treatment_column_name()\n",
    "            \n",
    "#         self.assertTrue('Invalid input error. Treatment column name does not'\\\n",
    "#                         ' exist' in str(treatment_column_name.exception))\n",
    "\n",
    "#     def test_false_outcome_column_name(self):\n",
    "#         def broken_outcome_column_name():\n",
    "#             res_post_new1 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     outcome_column_name= '1232114',\n",
    "#                                     C = 0.1,\n",
    "#                                     conn = conn,\n",
    "#                                     matching_option = 0,\n",
    "#                                     verbose = 3,\n",
    "#                                     k = 0\n",
    "#                                     )\n",
    "\n",
    "#         with self.assertRaises(Exception) as outcome_column_name:\n",
    "#             broken_outcome_column_name()\n",
    "            \n",
    "#         self.assertTrue('Invalid input error. Outcome column name does not'\\\n",
    "#                         ' exist' in str(outcome_column_name.exception))\n",
    "        \n",
    "\n",
    "        \n",
    "#     def test_false_early_stop_un_t_frac(self):\n",
    "#         def broken_early_stop_un_t_frac():\n",
    "#             res_post_new1 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     C = 0.1,\n",
    "#                                     conn = conn,\n",
    "#                                     matching_option = 0,\n",
    "#                                     verbose = 3,\n",
    "#                                     early_stop_un_t_frac = -1,\n",
    "#                                     k = 0\n",
    "#                                     )\n",
    "\n",
    "#         with self.assertRaises(Exception) as early_stop_un_t_frac:\n",
    "#             broken_early_stop_un_t_frac()\n",
    "            \n",
    "#         self.assertTrue('The value provided for the early stopping critera '\\\n",
    "#                         'of proportion of unmatched treatment units needs to '\\\n",
    "#                         'be between 0.0 and 1.0' in str(early_stop_un_t_frac.exception))\n",
    "    \n",
    "#     def test_false_early_stop_un_c_frac(self):\n",
    "#         def broken_early_stop_un_c_frac():\n",
    "#             res_post_new1 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     C = 0.1,\n",
    "#                                     conn = conn,\n",
    "#                                     matching_option = 0,\n",
    "#                                     verbose = 3,\n",
    "#                                     early_stop_un_c_frac=-1,\n",
    "#                                     k = 0\n",
    "#                                     )\n",
    "\n",
    "#         with self.assertRaises(Exception) as early_stop_un_c_frac:\n",
    "#             broken_early_stop_un_c_frac()\n",
    "            \n",
    "#         self.assertTrue('The value provided for the early stopping critera '\\\n",
    "#                         'of proportion of unmatched control units needs to '\\\n",
    "#                         'be between 0.0 and 1.0' in str(early_stop_un_c_frac.exception))\n",
    "    \n",
    "\n",
    "#     def test_false_early_stop_pe(self):\n",
    "#         def broken_early_stop_pe():\n",
    "#             res_post_new1 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     C = 0.1,\n",
    "#                                     conn = conn,\n",
    "#                                     matching_option = 0,\n",
    "#                                     verbose = 3,\n",
    "#                                     early_stop_pe = -10,\n",
    "#                                     k = 0\n",
    "#                                     )\n",
    "\n",
    "#         with self.assertRaises(Exception) as early_stop_pe:\n",
    "#             broken_early_stop_pe()\n",
    "            \n",
    "#         self.assertTrue('The value provided for the early stopping critera '\\\n",
    "#                         'of PE needs to be non-negative ' in str(early_stop_pe.exception))\n",
    "\n",
    "#     def test_false_early_stop_pe_frac(self):\n",
    "#         def broken_early_stop_pe_frac():\n",
    "#             res_post_new1 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     C = 0.1,\n",
    "#                                     conn = conn,\n",
    "#                                     matching_option = 0,\n",
    "#                                     verbose = 3,\n",
    "#                                     early_stop_pe_frac=-1,\n",
    "#                                     k = 0\n",
    "#                                     )\n",
    "\n",
    "#         with self.assertRaises(Exception) as early_stop_pe_frac:\n",
    "#             broken_early_stop_pe_frac()\n",
    "            \n",
    "#         self.assertTrue('The value provided for the early stopping critera of'\\\n",
    "#                         ' proportion of PE needs to be between 0.0 and 1.0' in str(early_stop_pe_frac.exception))\n",
    "        \n",
    "        \n",
    "#     def test_false_weights_type(self):\n",
    "#         def broken_weights_type():\n",
    "#             res_post_new2 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     C = 0.1,\n",
    "#                                     conn = conn,\n",
    "#                                     matching_option = 2,\n",
    "#                                     adaptive_weights = 'safdsaf',\n",
    "#                                     verbose = 3,\n",
    "#                                     k = 0\n",
    "#                                     )\n",
    "#         with self.assertRaises(Exception) as _weights_type:\n",
    "#             broken_weights_type()\n",
    "            \n",
    "#         self.assertTrue(\"Invalid input error. The acceptable values for \"\\\n",
    "#                             \"the adaptive_weights parameter are 'ridge', \"\\\n",
    "#                             \"'decisiontree'. Additionally, \"\\\n",
    "#                             \"adaptive-weights may be 'False' along \"\\\n",
    "#                             \"with a weight array\" in str(_weights_type.exception))\n",
    "\n",
    "#     def test_false_weight_array_len(self):\n",
    "#         def broken_weight_array_len():\n",
    "#             res_post_new2 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     C = 0.1,\n",
    "#                                     conn = conn,\n",
    "#                                     adaptive_weights = False,\n",
    "#                                     matching_option = 2,\n",
    "#                                     weight_array = [1],\n",
    "#                                     verbose = 3,\n",
    "#                                     k = 0\n",
    "#                                     )\n",
    "#         with self.assertRaises(Exception) as weight_array_len:\n",
    "#             broken_weight_array_len()\n",
    "            \n",
    "#         self.assertTrue('Invalid input error. Weight array size not equal'\\\n",
    "#                             ' to number of columns in dataframe' in str(weight_array_len.exception))\n",
    "        \n",
    "        \n",
    "#     def test_false_weight_array_sum(self):\n",
    "#         def broken_weight_array_sum():\n",
    "#             res_post_new2 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     C = 0.1,\n",
    "#                                     conn = conn,\n",
    "#                                     adaptive_weights = False,\n",
    "#                                     matching_option = 2,\n",
    "#                                     weight_array = [1]*p,\n",
    "#                                     verbose = 3,\n",
    "#                                     k = 0\n",
    "#                                     )\n",
    "#         with self.assertRaises(Exception) as weight_array_sum:\n",
    "#             broken_weight_array_sum()\n",
    "            \n",
    "#         self.assertTrue('Invalid input error. Weight array values must '\\\n",
    "#                             'sum to 1.0' in str(weight_array_sum.exception))\n",
    "        \n",
    "        \n",
    "#     def test_false_alpha(self):\n",
    "#         def broken_alpha():\n",
    "#             res_post_new2 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     C = 0.1,\n",
    "#                                     conn = conn,\n",
    "#                                     alpha = -10,\n",
    "#                                     verbose = 3,\n",
    "#                                     k = 0\n",
    "#                                     )\n",
    "#         with self.assertRaises(Exception) as alpha:\n",
    "#             broken_alpha()\n",
    "            \n",
    "#         self.assertTrue('Invalid input error. The alpha needs to be '\\\n",
    "#                             'positive for ridge regressions.' in str(alpha.exception))\n",
    "        \n",
    "        \n",
    "#     def test_false_C(self):\n",
    "#         def broken_C():\n",
    "#             res_post_new2 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     C = -10,\n",
    "#                                     conn = conn,\n",
    "#                                     verbose = 3,\n",
    "#                                     k = 0\n",
    "#                                     )\n",
    "#         with self.assertRaises(Exception) as C:\n",
    "#             broken_C()\n",
    "            \n",
    "#         self.assertTrue('The C, or the hyperparameter to trade-off between'\\\n",
    "#                            ' balancing factor and predictive error must be '\\\n",
    "#                            ' nonnegative. 'in str(C.exception))\n",
    "\n",
    "#     def test_false_k(self):\n",
    "#         def broken_k():\n",
    "#             res_post_new2 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     conn = conn,\n",
    "#                                     verbose = 3,\n",
    "#                                     k = -10\n",
    "#                                     )\n",
    "#         with self.assertRaises(Exception) as k:\n",
    "#             broken_k()\n",
    "            \n",
    "#         self.assertTrue('Invalid input error. The k must be'\\\n",
    "#             'a postive integer.'in str(k.exception))\n",
    "\n",
    "        \n",
    "#     def test_false_ratio(self):\n",
    "#         def broken_ratio():\n",
    "#             res_post_new2 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     conn = conn,\n",
    "#                                     verbose = 3,\n",
    "#                                     ratio = -10\n",
    "#                                     )\n",
    "#         with self.assertRaises(Exception) as ratio:\n",
    "#             broken_ratio()\n",
    "            \n",
    "#         self.assertTrue('Invalid input error. ratio value must '\\\n",
    "#                             'be positive and smaller than 1.0 \\n'\\\n",
    "#                         'Recommended 0.01 and please do not adjust it unless necessary 'in str(ratio.exception))\n",
    "        \n",
    "        \n",
    "#     def test_false_matching_option(self):\n",
    "#         def broken_matching_option():\n",
    "#             res_post_new2 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     conn = conn,\n",
    "#                                     verbose = 3,\n",
    "#                                     matching_option = -10\n",
    "#                                     )\n",
    "#         with self.assertRaises(Exception) as matching_option:\n",
    "#             broken_matching_option()\n",
    "            \n",
    "#         self.assertTrue('Invalid input error. matching_option value must '\\\n",
    "#             'be 0, 1, 2 or 3'in str(matching_option.exception))\n",
    "        \n",
    "#     def test_false_verbose(self):\n",
    "#         def broken_verbose():\n",
    "#             res_post_new2 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     conn = conn,\n",
    "#                                     verbose = 10\n",
    "#                                     )\n",
    "#         with self.assertRaises(Exception) as verbose:\n",
    "#             broken_verbose()\n",
    "            \n",
    "#         self.assertTrue('Invalid input error. The verbose option must be'\\\n",
    "#                         'the integer 0,1,2 or 3.'in str(verbose.exception))\n",
    "                \n",
    "#     def test_false_max_depth(self):\n",
    "#         def broken_max_depth():\n",
    "#             res_post_new2 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     conn = conn,\n",
    "#                                     max_depth = -10\n",
    "#                                     )\n",
    "#         with self.assertRaises(Exception) as max_depth:\n",
    "#             broken_max_depth()\n",
    "            \n",
    "#         self.assertTrue('Invalid input error. The max_depth must be'\\\n",
    "#                 'a postive integer.'in str(max_depth.exception))\n",
    "        \n",
    "#     def test_false_random_state(self):\n",
    "#         def broken_random_state():\n",
    "#             res_post_new2 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     conn = conn,\n",
    "#                                     random_state = -10000\n",
    "#                                     )\n",
    "#         with self.assertRaises(Exception) as random_state:\n",
    "#             broken_random_state()\n",
    "            \n",
    "#         self.assertTrue('Invalid input error. The random_state  must be'\\\n",
    "#                 'a postive integer or None.'in str(random_state.exception))\n",
    "\n",
    "        \n",
    "        \n",
    "#     def test_false_missing_data_replace(self):\n",
    "#         def broken_missing_data_replace():\n",
    "#             res_post_new2 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     conn = conn,\n",
    "#                                     missing_data_replace =4\n",
    "#                                     )\n",
    "#         with self.assertRaises(Exception) as missing_data_replace:\n",
    "#             broken_missing_data_replace()\n",
    "            \n",
    "#         self.assertTrue('Invalid input error. missing_data_replace value must '\\\n",
    "#             'be 0, 1 or 2'in str(missing_data_replace.exception))\n",
    "        \n",
    "#     def test_false_missing_holdout_replace(self):\n",
    "#         def broken_missing_holdout_replace():\n",
    "#             res_post_new2 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     conn = conn,\n",
    "#                                     missing_holdout_replace =4\n",
    "#                                     )\n",
    "#         with self.assertRaises(Exception) as missing_holdout_replace:\n",
    "#             broken_missing_holdout_replace()\n",
    "            \n",
    "#         self.assertTrue('Invalid input error. missing_holdout_replace value must '\\\n",
    "#             'be 0, or 1'in str(missing_holdout_replace.exception))\n",
    "        \n",
    "    \n",
    "        \n",
    "#     def test_false_treatment_column_name_value(self):\n",
    "#         def broken_treatment_column_name_value():\n",
    "#             df = holdout.copy()\n",
    "#             df.loc[0,'treated'] = 4\n",
    "#             res_post_new1 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = df, # holdout set\n",
    "#                                     C = 0.1,\n",
    "#                                     conn = conn,\n",
    "#                                     matching_option = 0,\n",
    "#                                     verbose = 3,\n",
    "#                                     k = 0\n",
    "#                                     )\n",
    "\n",
    "#         with self.assertRaises(Exception) as treatment_column_name_value:\n",
    "#             broken_treatment_column_name_value()\n",
    "#         self.assertTrue('Invalid input error. All rows in the treatment '\\\n",
    "#                         'column must have either a 0 or a 1 value.' in str(treatment_column_name_value.exception))\n",
    "        \n",
    "#     def test_false_input_treatment_value(self):\n",
    "#         def broken_input_treatment_value():\n",
    "#             df = data.copy()\n",
    "#             df.loc[0,'treated'] = 4\n",
    "#             insert_data_to_db(\"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                     df,\n",
    "#                     treatment_column_name= \"treated\",\n",
    "#                     outcome_column_name= 'outcome',conn = conn)\n",
    "            \n",
    "#             res_post_new2 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     conn = conn\n",
    "#                                     )\n",
    "#         with self.assertRaises(Exception) as input_treatment_value:\n",
    "#             broken_input_treatment_value()\n",
    "            \n",
    "#         self.assertTrue('Invalid input error. All rows in the treatment '\\\n",
    "#                         'column must have either a 0 or a 1 value.'in str(input_treatment_value.exception))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_post_new1 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     treatment_column_name= \"sadfdag\",\n",
    "# #                                     C = 0.1,\n",
    "#                                     conn = conn,\n",
    "#                                     matching_option = 0,\n",
    "#                                     verbose = 3,\n",
    "#                                     k = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_post_new2 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                         holdout_data = holdout, # holdout set\n",
    "#                         C = 0.1,\n",
    "#                         conn = conn,\n",
    "#                         alpha = -10,\n",
    "#                         verbose = 3,\n",
    "#                         k = 0\n",
    "#                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_post_new1 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                                     holdout_data = holdout, # holdout set\n",
    "#                                     treatment_column_name= \"sadfdag\",\n",
    "#                                     C = 0.1,\n",
    "#                                     conn = conn,\n",
    "#                                     matching_option = 0,\n",
    "#                                     verbose = 3,\n",
    "#                                     k = 0\n",
    "#                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_post_new1 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                         holdout_data = holdout, # holdout set\n",
    "#                         C = 0.1,\n",
    "#                         conn = conn,\n",
    "#                         matching_option = 0,\n",
    "#                         verbose = 3,\n",
    "#                         early_stop_un_t_frac = -10,\n",
    "#                         k = 0\n",
    "#                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = holdout.copy()\n",
    "# df.loc[0,'treated'] = 4\n",
    "# res_post_new1 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                         holdout_data = df, # holdout set\n",
    "#                         C = 0.1,\n",
    "#                         conn = conn,\n",
    "#                         matching_option = 0,\n",
    "#                         verbose = 1,\n",
    "#                         k = 0\n",
    "#                         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# t = Test_exceptions()\n",
    "\n",
    "# t.test_false_dataset()\n",
    "# t.test_false_holdout()\n",
    "# t.test_false_treatment_column_name()\n",
    "# t.test_false_outcome_column_name()\n",
    "# t.test_false_early_stop_un_t_frac()    \n",
    "# t.test_false_early_stop_un_c_frac()             \n",
    "# t.test_false_early_stop_pe()    \n",
    "# t.test_false_early_stop_pe_frac()  \n",
    "# t.test_false_weights_type()  \n",
    "# t.test_false_weight_array_len()    \n",
    "# t.test_false_weight_array_sum()        \n",
    "# t.test_false_alpha()\n",
    "# t.test_false_C()     \n",
    "# t.test_false_k()\n",
    "# t.test_false_ratio()\n",
    "# t.test_false_matching_option()\n",
    "# t.test_false_verbose()   \n",
    "# t.test_false_max_depth() \n",
    "# t.test_false_random_state()    \n",
    "# t.test_false_missing_data_replace()   \n",
    "# t.test_false_missing_holdout_replace() \n",
    "\n",
    "# t.test_false_input_treatment_value()     \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
