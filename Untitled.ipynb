{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gen_insert_data import *\n",
    "from FLAME_db_algorithm import *\n",
    "from matching_helpers import *\n",
    "from utils import *\n",
    "\n",
    "\n",
    "#Generate toy dataset\n",
    "p = 4\n",
    "TE = 5\n",
    "data,weight_array = gen_data_db(n = 5000,p = p, TE = TE)\n",
    "holdout,weight_array = gen_data_db(n = 500,p = p, TE = TE)\n",
    "\n",
    "\n",
    "#Connect to the database\n",
    "select_db = \"postgreSQL\"  # Select the database you are using\n",
    "database_name='tmp' # database name\n",
    "host ='vcm-17819.vm.duke.edu' # \"127.0.0.1\"\n",
    "port = \"5432\"\n",
    "user=\"newuser\"\n",
    "password= \"sunxian123\"\n",
    "conn = connect_db(database_name, user, password, host, port)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert 5000 rows successfully to Database\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Level1: Do matching without dropping any covs\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349763\n",
      "4.98870839266607\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "4.988481490349763\n",
      "4.98870839266607\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349745\n",
      "4.988708392666051\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Level1: Do matching without dropping any covs\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349751\n",
      "4.988708392666057\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Level1: Do matching without dropping any covs\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349751\n",
      "4.988708392666057\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Level1: Do matching without dropping any covs\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349751\n",
      "4.988708392666057\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Level1: Do matching without dropping any covs\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349751\n",
      "4.988708392666057\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Level1: Do matching without dropping any covs\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349757\n",
      "4.988708392666063\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349745\n",
      "4.988708392666051\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349757\n",
      "4.988708392666063\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349757\n",
      "4.988708392666064\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349757\n",
      "4.988708392666064\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Level1: Do matching without dropping any covs\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349757\n",
      "4.988708392666064\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Level1: Do matching without dropping any covs\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349757\n",
      "4.988708392666064\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349757\n",
      "4.988708392666064\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349757\n",
      "4.988708392666064\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349757\n",
      "4.988708392666064\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349757\n",
      "4.988708392666064\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349757\n",
      "4.988708392666064\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349757\n",
      "4.988708392666064\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349757\n",
      "4.988708392666064\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349757\n",
      "4.988708392666064\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349757\n",
      "4.988708392666064\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349757\n",
      "4.988708392666064\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349757\n",
      "4.988708392666064\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349764\n",
      "4.988708392666069\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349764\n",
      "4.988708392666069\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349771\n",
      "4.9887083926660765\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349771\n",
      "4.9887083926660765\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349757\n",
      "4.988708392666063\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349764\n",
      "4.988708392666069\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349764\n",
      "4.988708392666069\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349764\n",
      "4.988708392666069\n",
      "There is missing data in this dataset. The default missing data handling is being done, so we are not matching on any missing values in the matching set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5008\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  16 out of a total of  2504 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988481490349764\n",
      "4.988708392666069\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5004\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  0 out of a total of  2484 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988447797267449\n",
      "4.988708392666044\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5004\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  0 out of a total of  2484 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988447797267449\n",
      "4.988708392666044\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5004\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  0 out of a total of  2484 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988447797267449\n",
      "4.988708392666044\n",
      "Early stopping: All control units matched\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  5004\n",
      "\tNumber of covariates dropped in total:  1\n",
      "\tNumber of matched groups formed in total:  16\n",
      "\tUnmatched treated units:  0 out of a total of  2484 treated units\n",
      "\tUnmatched control units:  0 out of a total of  2520 control units\n",
      "4.988447797267461\n",
      "4.988708392666055\n"
     ]
    }
   ],
   "source": [
    "#Insert the data into database\n",
    "insert_data_to_db(\"test_df\", # The name of your table containing the dataset to be matched\n",
    "                    data, \n",
    "                    treatment_column_name= \"Treated\",\n",
    "                    outcome_column_name= 'outcome123',conn = conn)\n",
    "\n",
    "\n",
    "#**********************************Test**********************************#\n",
    "\n",
    "#Test fixed weights\n",
    "res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "                holdout_data = holdout, # holdout set\n",
    "                treatment_column_name= \"Treated\",\n",
    "                outcome_column_name= 'outcome123',\n",
    "                C = 0,\n",
    "                conn = conn,\n",
    "                matching_option = 3,\n",
    "                adaptive_weights = False,\n",
    "                weight_array = weight_array,        \n",
    "                verbose = 2,\n",
    "                k = 0\n",
    "                )\n",
    "print(ATE_db(res_post_new))\n",
    "print(ATT_db(res_post_new))\n",
    "for verbose in [0,1,2,3]:\n",
    "    res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "                    holdout_data = holdout, # holdout set\n",
    "                    treatment_column_name= \"Treated\",\n",
    "                    outcome_column_name= 'outcome123',\n",
    "                    C = 0,\n",
    "                    conn = conn,\n",
    "                    matching_option = 3,\n",
    "                    adaptive_weights = 'ridge',\n",
    "                    verbose = verbose,\n",
    "                    k = 0\n",
    "                    )\n",
    "    print(ATE_db(res_post_new))\n",
    "    print(ATT_db(res_post_new))\n",
    "    \n",
    "for C in [0.0, 0.2,0.6]:\n",
    "    res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "                    holdout_data = holdout, # holdout set\n",
    "                    treatment_column_name= \"Treated\",\n",
    "                    outcome_column_name= 'outcome123',\n",
    "                    C = C,\n",
    "                    conn = conn,\n",
    "                    matching_option = 1,\n",
    "                    adaptive_weights = 'ridge',\n",
    "                    verbose = verbose,\n",
    "                    k = 0\n",
    "                    )\n",
    "    print(ATE_db(res_post_new))\n",
    "    print(ATT_db(res_post_new))\n",
    "for matching_option in [0,1,2,3]: \n",
    "    res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "                    holdout_data = holdout, # holdout set\n",
    "                    treatment_column_name= \"Treated\",\n",
    "                    outcome_column_name= 'outcome123',\n",
    "                    C = 0.0,\n",
    "                    conn = conn,\n",
    "                    matching_option = matching_option,\n",
    "                    adaptive_weights = 'ridge',\n",
    "                    verbose = 1,\n",
    "                    k = 0\n",
    "                    )\n",
    "    print(ATE_db(res_post_new))\n",
    "    print(ATT_db(res_post_new))\n",
    "for adaptive_weights in ['ridge', 'decisiontree']:\n",
    "    res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "                holdout_data = holdout, # holdout set\n",
    "                treatment_column_name= \"Treated\",\n",
    "                outcome_column_name= 'outcome123',\n",
    "                C = 0,\n",
    "                conn = conn,\n",
    "                matching_option = 1,\n",
    "                adaptive_weights = adaptive_weights,\n",
    "                verbose = verbose,\n",
    "                k = 0\n",
    "                )\n",
    "    print(ATE_db(res_post_new))\n",
    "    print(ATT_db(res_post_new))\n",
    "for alpha in [0.1,0.8]:\n",
    "    res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "                holdout_data = holdout, # holdout set\n",
    "                treatment_column_name= \"Treated\",\n",
    "                outcome_column_name= 'outcome123',\n",
    "                C = 0,\n",
    "                conn = conn,\n",
    "                matching_option = 1,\n",
    "                adaptive_weights = 'decisiontree',\n",
    "                verbose = 1,\n",
    "                k = 0,\n",
    "                alpha = alpha,\n",
    "                early_stop_iterations = 2            \n",
    "                )\n",
    "    print(ATE_db(res_post_new))\n",
    "    print(ATT_db(res_post_new))\n",
    "for max_depth in [8,9]:\n",
    "    res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "                holdout_data = holdout, # holdout set\n",
    "                treatment_column_name= \"Treated\",\n",
    "                outcome_column_name= 'outcome123',\n",
    "                C = 0,\n",
    "                conn = conn,\n",
    "                matching_option = 1,\n",
    "                adaptive_weights = 'decisiontree',\n",
    "                verbose = 1,\n",
    "                k = 0,\n",
    "                max_depth = max_depth,\n",
    "                early_stop_iterations = 2            \n",
    "                )\n",
    "    print(ATE_db(res_post_new))\n",
    "    print(ATT_db(res_post_new))\n",
    "    \n",
    "for early_stop_iterations in [2,3]:\n",
    "    res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "                holdout_data = holdout, # holdout set\n",
    "                treatment_column_name= \"Treated\",\n",
    "                outcome_column_name= 'outcome123',\n",
    "                C = 0,\n",
    "                conn = conn,\n",
    "                matching_option = 1,\n",
    "                adaptive_weights = 'decisiontree',\n",
    "                verbose = 1,\n",
    "                k = 0,\n",
    "                early_stop_iterations = early_stop_iterations            \n",
    "                )\n",
    "    print(ATE_db(res_post_new))\n",
    "    print(ATT_db(res_post_new))\n",
    "for k in [0,2,4]:\n",
    "    res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "                holdout_data = holdout, # holdout set\n",
    "                treatment_column_name= \"Treated\",\n",
    "                outcome_column_name= 'outcome123',\n",
    "                C = 0,\n",
    "                conn = conn,\n",
    "                matching_option = 1,\n",
    "                adaptive_weights = 'decisiontree',\n",
    "                verbose = 1,\n",
    "                k = k\n",
    "                )\n",
    "    print(ATE_db(res_post_new))\n",
    "    print(ATT_db(res_post_new))\n",
    "for ratio in [0.01,0.1]:\n",
    "    res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "                holdout_data = holdout, # holdout set\n",
    "                treatment_column_name= \"Treated\",\n",
    "                outcome_column_name= 'outcome123',\n",
    "                C = 0,\n",
    "                conn = conn,\n",
    "                matching_option = 1,\n",
    "                adaptive_weights = 'decisiontree',\n",
    "                verbose = 1,\n",
    "                ratio = ratio\n",
    "                )\n",
    "    print(ATE_db(res_post_new))\n",
    "    print(ATT_db(res_post_new))\n",
    "for early_stop_un_c_frac in [0.2,0.5]:\n",
    "    res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "            holdout_data = holdout, # holdout set\n",
    "            treatment_column_name= \"Treated\",\n",
    "            outcome_column_name= 'outcome123',\n",
    "            C = 0,\n",
    "            conn = conn,\n",
    "            matching_option = 1,\n",
    "            adaptive_weights = 'decisiontree',\n",
    "            verbose = 1,\n",
    "            early_stop_un_c_frac = early_stop_un_c_frac                \n",
    "            )\n",
    "    print(ATE_db(res_post_new))\n",
    "    print(ATT_db(res_post_new))\n",
    "    \n",
    "for early_stop_un_t_frac in [0.2,0.5]:\n",
    "    res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "            holdout_data = holdout, # holdout set\n",
    "            treatment_column_name= \"Treated\",\n",
    "            outcome_column_name= 'outcome123',\n",
    "            C = 0,\n",
    "            conn = conn,\n",
    "            matching_option = 1,\n",
    "            adaptive_weights = 'decisiontree',\n",
    "            verbose = 1,\n",
    "            early_stop_un_t_frac = early_stop_un_t_frac                \n",
    "            )\n",
    "    print(ATE_db(res_post_new))\n",
    "    print(ATT_db(res_post_new))\n",
    "for early_stop_pe in [3,5]:\n",
    "    res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "            holdout_data = holdout, # holdout set\n",
    "            treatment_column_name= \"Treated\",\n",
    "            outcome_column_name= 'outcome123',\n",
    "            C = 0,\n",
    "            conn = conn,\n",
    "            matching_option = 1,\n",
    "            adaptive_weights = 'decisiontree',\n",
    "            verbose = 1,\n",
    "            early_stop_pe = early_stop_pe                \n",
    "            )\n",
    "    print(ATE_db(res_post_new))\n",
    "    print(ATT_db(res_post_new))\n",
    "for early_stop_pe_frac in [0.5,1]:    \n",
    "    res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "            holdout_data = holdout, # holdout set\n",
    "            treatment_column_name= \"Treated\",\n",
    "            outcome_column_name= 'outcome123',\n",
    "            C = 0,\n",
    "            conn = conn,\n",
    "            matching_option = 1,\n",
    "            adaptive_weights = 'decisiontree',\n",
    "            verbose = 1,\n",
    "            early_stop_pe_frac = early_stop_pe_frac                \n",
    "            )   \n",
    "    print(ATE_db(res_post_new))\n",
    "    print(ATT_db(res_post_new))\n",
    "for missing_data_replace in [0,1,2]:\n",
    "    res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "            holdout_data = holdout, # holdout set\n",
    "            treatment_column_name= \"Treated\",\n",
    "            outcome_column_name= 'outcome123',\n",
    "            C = 0,\n",
    "            conn = conn,\n",
    "            matching_option = 1,\n",
    "            adaptive_weights = 'decisiontree',\n",
    "            verbose = 1,\n",
    "            missing_data_replace = missing_data_replace                \n",
    "            ) \n",
    "    print(ATE_db(res_post_new))\n",
    "    print(ATT_db(res_post_new))\n",
    "for missing_holdout_replace in [0,1]:    \n",
    "    res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "            holdout_data = holdout, # holdout set\n",
    "            treatment_column_name= \"Treated\",\n",
    "            outcome_column_name= 'outcome123',\n",
    "            C = 0,\n",
    "            conn = conn,\n",
    "            matching_option = 1,\n",
    "            adaptive_weights = 'decisiontree',\n",
    "            verbose = 1,\n",
    "            missing_holdout_replace = missing_holdout_replace                \n",
    "            )\n",
    "    print(ATE_db(res_post_new))\n",
    "    print(ATT_db(res_post_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pip' has no attribute 'get_installed_distributions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fd9ce26928b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpip\u001b[0m \u001b[0;31m#needed to use the pip functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_installed_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pip' has no attribute 'get_installed_distributions'"
     ]
    }
   ],
   "source": [
    "import pip #needed to use the pip functions\n",
    "for i in pip.get_installed_distributions(local_only=True):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyodbc\n",
      "  Downloading pyodbc-4.0.30-cp37-cp37m-macosx_10_9_x86_64.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 601 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pyodbc\n",
      "Successfully installed pyodbc-4.0.30\n"
     ]
    }
   ],
   "source": [
    "!pip install pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyodbc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-60a2c14351b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyodbc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyodbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyodbc'"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "print(pyodbc.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
