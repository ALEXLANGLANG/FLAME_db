{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert 5000 rows successfully to Database\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flame_db.gen_insert_data import *\n",
    "from flame_db.FLAME_db_algorithm import *\n",
    "from flame_db.matching_helpers import *\n",
    "from flame_db.utils import *\n",
    "import unittest\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "#Generate toy dataset\n",
    "p = 20\n",
    "TE = 5\n",
    "data,weight_array = gen_data_db(n = 5000,p = p, TE = TE)\n",
    "holdout,weight_array = gen_data_db(n = 500,p = p, TE = TE)\n",
    "#Connect to the database\n",
    "select_db = \"postgreSQL\"  # Select the database you are using\n",
    "database_name='tmp' # database name\n",
    "host ='vcm-17819.vm.duke.edu' # \"127.0.0.1\"\n",
    "port = \"5432\"\n",
    "user=\"newuser\"\n",
    "password= \"sunxian123\"\n",
    "conn = connect_db(database_name, user, password, host, port)\n",
    "\n",
    "#Insert the data into database\n",
    "insert_data_to_db(\"test_df\", # The name of your table containing the dataset to be matched\n",
    "                    data, \n",
    "                    treatment_column_name= \"Treated\",\n",
    "                    outcome_column_name= 'outcome123',conn = conn)\n",
    "\n",
    "\n",
    "\n",
    "def check_statistics(res_post_new):\n",
    "    ATE_ = ATE_db(res_post_new)\n",
    "    ATT_ = ATT_db(res_post_new)\n",
    "    if type(ATE_) == np.nan:\n",
    "        print(\"ATE: \" + str(ATE_))\n",
    "        return True\n",
    "    if type(ATT_) == np.nan:\n",
    "        print(\"ATT:\" + str(ATT_))\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestFlame_db(unittest.TestCase):\n",
    "              \n",
    "    def test_weights(self):\n",
    "        is_corrct = 1\n",
    "        try:\n",
    "            for verbose in [0,1,2,3]:\n",
    "                for matching_option in [0,1,2,3]:\n",
    "                    #Test fixed weights\n",
    "                    for adaptive_weights in ['ridge', 'decisiontree',False]:\n",
    "                        res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "                                    holdout_data = holdout, # holdout set\n",
    "                                    treatment_column_name= \"Treated\",\n",
    "                                    outcome_column_name= 'outcome123',\n",
    "                                    C = 0.1,\n",
    "                                    conn = conn,\n",
    "                                    matching_option = matching_option,\n",
    "                                    adaptive_weights = adaptive_weights,\n",
    "                                    weight_array = weight_array, \n",
    "                                    verbose = verbose,\n",
    "                                    k = 0\n",
    "                                    )\n",
    "                        if check_statistics(res_post_new):\n",
    "                            is_corrct = 0\n",
    "            \n",
    "        except (KeyError, ValueError):\n",
    "                is_corrct = 0\n",
    "\n",
    "        self.assertEqual(1, is_corrct,\n",
    "                             msg='Error when test weights')        \n",
    "            \n",
    "    def test_stop_iterations(self):\n",
    "        is_corrct = 1\n",
    "        try:\n",
    "            for early_stop_iterations in [2,3]:\n",
    "                res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "                            holdout_data = holdout, # holdout set\n",
    "                            treatment_column_name= \"Treated\",\n",
    "                            outcome_column_name= 'outcome123',\n",
    "                            C = 0.1,\n",
    "                            conn = conn,\n",
    "                            matching_option = 0,\n",
    "                            adaptive_weights = 'decisiontree',\n",
    "                            verbose = 1,\n",
    "                            k = 0,\n",
    "                            early_stop_iterations = early_stop_iterations            \n",
    "                            )\n",
    "                if check_statistics(res_post_new):\n",
    "                    is_corrct = 0\n",
    "            \n",
    "        except (KeyError, ValueError):\n",
    "                is_corrct = 0\n",
    "\n",
    "        self.assertEqual(1, is_corrct,\n",
    "                             msg='Error when test stop_iterations')        \n",
    "\n",
    "    def test_missing_datasets(self):\n",
    "            is_corrct = 1\n",
    "            try:    \n",
    "                for missing_data_replace in [0,1,2]:\n",
    "                    for missing_holdout_replace in [0,1]:  \n",
    "                        holdout_miss = holdout.copy()\n",
    "                        m,n = holdout_miss.shape\n",
    "                        for i in range(int(m/100)):\n",
    "                            for j in [0,int(n/2)]:\n",
    "                                holdout_miss.iloc[i,j] = np.nan\n",
    "                        res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "                                                holdout_data = holdout_miss, # holdout set\n",
    "                                                treatment_column_name= \"Treated\",\n",
    "                                                outcome_column_name= 'outcome123',\n",
    "                                                C = 0,\n",
    "                                                conn = conn,\n",
    "                                                matching_option = 1,\n",
    "                                                adaptive_weights = 'decisiontree',\n",
    "                                                verbose = 1,\n",
    "                                                missing_data_replace = missing_data_replace,\n",
    "                                                missing_holdout_replace = missing_holdout_replace) \n",
    "                        if check_statistics(res_post_new):\n",
    "                            is_corrct = 0\n",
    "\n",
    "            except (KeyError, ValueError):\n",
    "                    is_corrct = 0\n",
    "\n",
    "            self.assertEqual(1, is_corrct,\n",
    "                                 msg='Error when test missing datasets')  \n",
    "\n",
    "        #     print(ATE_db(res_post_new))\n",
    "        #     print(ATT_db(res_post_new))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert 5000 rows successfully to Database\n",
      "*****************************************************\n",
      "before\n",
      "2520\n",
      "2480\n",
      "after\n",
      "2509\n",
      "2469\n",
      "Level1: Do matching without dropping any covs\n",
      "Level2: No matching after fast drop cov11 with adaptive score: (PE: 1.9388623028391656 BF: 0.0032143497665189443)\n",
      "Level3: No matching after fast drop cov19 with adaptive score: (PE: 1.917527084383725 BF: 0.012857399066075777)\n",
      "Level4: No matching after fast drop cov18 with adaptive score: (PE: 1.8979338755195094 BF: 0.038572197198227326)\n",
      "Level5: No matching after fast drop cov17 with adaptive score: (PE: 1.8805541575074818 BF: 0.07152573941586715)\n",
      "Level6: No matching after fast drop cov14 with adaptive score: (PE: 1.875972097181229 BF: 0.15388376651668412)\n",
      "Level7: No matching after fast drop cov20 with adaptive score: (PE: 1.8738657337779268 BF: 0.3021488780527808)\n",
      "Level8: No matching after fast drop cov12 with adaptive score: (PE: 1.877703681271929 BF: 0.5303612543648051)\n",
      "Level9: No matching after fast drop cov13 with adaptive score: (PE: 1.8876500091401778 BF: 0.9209434936617807)\n",
      "Level10: No matching after fast drop cov16 with adaptive score: (PE: 1.8963767477404594 BF: 1.4215332700213619)\n",
      "*****************************************************\n",
      "before\n",
      "2509\n",
      "2469\n",
      "after\n",
      "738\n",
      "702\n",
      "Found the boundary to switch to slowly dropping important covariates.\n",
      "Level11: Do matching after slow drop cov15 with adaptive score: (PE: 1.902637183120416 BF: 0.45014245014245013)\n",
      "*****************************************************\n",
      "before\n",
      "738\n",
      "702\n",
      "after\n",
      "-1197\n",
      "-1225\n",
      "Early stopping: predictive error would have risen  25.0 % above the baseline.\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  7422\n",
      "\tNumber of covariates dropped in total:  11\n",
      "\tNumber of matched groups formed in total:  1889\n",
      "\tUnmatched treated units:  -1225 out of a total of  2480 treated units\n",
      "\tUnmatched control units:  -1197 out of a total of  2520 control units\n"
     ]
    }
   ],
   "source": [
    "p = 20\n",
    "TE = 5\n",
    "data,weight_array = gen_data_db(n = 5000,p = p, TE = TE)\n",
    "holdout,weight_array = gen_data_db(n = 500,p = p, TE = TE)\n",
    "#Connect to the database\n",
    "select_db = \"postgreSQL\"  # Select the database you are using\n",
    "database_name='tmp' # database name\n",
    "host ='vcm-17819.vm.duke.edu' # \"127.0.0.1\"\n",
    "port = \"5432\"\n",
    "user=\"newuser\"\n",
    "password= \"sunxian123\"\n",
    "conn = connect_db(database_name, user, password, host, port)\n",
    "\n",
    "#Insert the data into database\n",
    "insert_data_to_db(\"test_df\", # The name of your table containing the dataset to be matched\n",
    "                    data, \n",
    "                    treatment_column_name= \"Treated\",\n",
    "                    outcome_column_name= 'outcome123',conn = conn)\n",
    "for verbose in [2]:\n",
    "    for matching_option in [0]:\n",
    "        #Test fixed weights\n",
    "        for adaptive_weights in ['ridge']:\n",
    "            res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "                        holdout_data = holdout, # holdout set\n",
    "                        treatment_column_name= \"Treated\",\n",
    "                        outcome_column_name= 'outcome123',\n",
    "                        C = 0.1,\n",
    "                        conn = conn,\n",
    "                        matching_option = matching_option,\n",
    "                        adaptive_weights = adaptive_weights,\n",
    "                        weight_array = weight_array, \n",
    "                        verbose = verbose,\n",
    "                        k = 0\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# t = TestFlame_db()\n",
    "# t.test_weights()\n",
    "# t.test_stop_iterations()\n",
    "# t.test_missing_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# #**********************************Test**********************************#\n",
    "\n",
    "\n",
    "    \n",
    "# for C in [0.0, 0.2,0.6]:\n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                     holdout_data = holdout, # holdout set\n",
    "#                     treatment_column_name= \"Treated\",\n",
    "#                     outcome_column_name= 'outcome123',\n",
    "#                     C = C,\n",
    "#                     conn = conn,\n",
    "#                     matching_option = 1,\n",
    "#                     adaptive_weights = 'ridge',\n",
    "#                     verbose = verbose,\n",
    "#                     k = 0\n",
    "#                     )\n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "# for matching_option in [0,1,2,3]: \n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                     holdout_data = holdout, # holdout set\n",
    "#                     treatment_column_name= \"Treated\",\n",
    "#                     outcome_column_name= 'outcome123',\n",
    "#                     C = 0.0,\n",
    "#                     conn = conn,\n",
    "#                     matching_option = matching_option,\n",
    "#                     adaptive_weights = 'ridge',\n",
    "#                     verbose = 1,\n",
    "#                     k = 0\n",
    "#                     )\n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "\n",
    "\n",
    "# for alpha in [0.1,0.8]:\n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                 holdout_data = holdout, # holdout set\n",
    "#                 treatment_column_name= \"Treated\",\n",
    "#                 outcome_column_name= 'outcome123',\n",
    "#                 C = 0,\n",
    "#                 conn = conn,\n",
    "#                 matching_option = 1,\n",
    "#                 adaptive_weights = 'decisiontree',\n",
    "#                 verbose = 1,\n",
    "#                 k = 0,\n",
    "#                 alpha = alpha,\n",
    "#                 early_stop_iterations = 2            \n",
    "#                 )\n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "# for max_depth in [8,9]:\n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                 holdout_data = holdout, # holdout set\n",
    "#                 treatment_column_name= \"Treated\",\n",
    "#                 outcome_column_name= 'outcome123',\n",
    "#                 C = 0,\n",
    "#                 conn = conn,\n",
    "#                 matching_option = 1,\n",
    "#                 adaptive_weights = 'decisiontree',\n",
    "#                 verbose = 1,\n",
    "#                 k = 0,\n",
    "#                 max_depth = max_depth,\n",
    "#                 early_stop_iterations = 2            \n",
    "#                 )\n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "    \n",
    "\n",
    "# for k in [0,2,4]:\n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                 holdout_data = holdout, # holdout set\n",
    "#                 treatment_column_name= \"Treated\",\n",
    "#                 outcome_column_name= 'outcome123',\n",
    "#                 C = 0,\n",
    "#                 conn = conn,\n",
    "#                 matching_option = 1,\n",
    "#                 adaptive_weights = 'decisiontree',\n",
    "#                 verbose = 1,\n",
    "#                 k = k\n",
    "#                 )\n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "# for ratio in [0.01,0.1]:\n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                 holdout_data = holdout, # holdout set\n",
    "#                 treatment_column_name= \"Treated\",\n",
    "#                 outcome_column_name= 'outcome123',\n",
    "#                 C = 0,\n",
    "#                 conn = conn,\n",
    "#                 matching_option = 1,\n",
    "#                 adaptive_weights = 'decisiontree',\n",
    "#                 verbose = 1,\n",
    "#                 ratio = ratio\n",
    "#                 )\n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "# for early_stop_un_c_frac in [0.2,0.5]:\n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#             holdout_data = holdout, # holdout set\n",
    "#             treatment_column_name= \"Treated\",\n",
    "#             outcome_column_name= 'outcome123',\n",
    "#             C = 0,\n",
    "#             conn = conn,\n",
    "#             matching_option = 1,\n",
    "#             adaptive_weights = 'decisiontree',\n",
    "#             verbose = 1,\n",
    "#             early_stop_un_c_frac = early_stop_un_c_frac                \n",
    "#             )\n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "    \n",
    "# for early_stop_un_t_frac in [0.2,0.5]:\n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#             holdout_data = holdout, # holdout set\n",
    "#             treatment_column_name= \"Treated\",\n",
    "#             outcome_column_name= 'outcome123',\n",
    "#             C = 0,\n",
    "#             conn = conn,\n",
    "#             matching_option = 1,\n",
    "#             adaptive_weights = 'decisiontree',\n",
    "#             verbose = 1,\n",
    "#             early_stop_un_t_frac = early_stop_un_t_frac                \n",
    "#             )\n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "# for early_stop_pe in [3,5]:\n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#             holdout_data = holdout, # holdout set\n",
    "#             treatment_column_name= \"Treated\",\n",
    "#             outcome_column_name= 'outcome123',\n",
    "#             C = 0,\n",
    "#             conn = conn,\n",
    "#             matching_option = 1,\n",
    "#             adaptive_weights = 'decisiontree',\n",
    "#             verbose = 1,\n",
    "#             early_stop_pe = early_stop_pe                \n",
    "#             )\n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "# for early_stop_pe_frac in [0.5,1]:    \n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#             holdout_data = holdout, # holdout set\n",
    "#             treatment_column_name= \"Treated\",\n",
    "#             outcome_column_name= 'outcome123',\n",
    "#             C = 0,\n",
    "#             conn = conn,\n",
    "#             matching_option = 1,\n",
    "#             adaptive_weights = 'decisiontree',\n",
    "#             verbose = 1,\n",
    "#             early_stop_pe_frac = early_stop_pe_frac                \n",
    "#             )   \n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "# for missing_data_replace in [0,1,2]:\n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#             holdout_data = holdout, # holdout set\n",
    "#             treatment_column_name= \"Treated\",\n",
    "#             outcome_column_name= 'outcome123',\n",
    "#             C = 0,\n",
    "#             conn = conn,\n",
    "#             matching_option = 1,\n",
    "#             adaptive_weights = 'decisiontree',\n",
    "#             verbose = 1,\n",
    "#             missing_data_replace = missing_data_replace                \n",
    "#             ) \n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "# for missing_holdout_replace in [0,1]:    \n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#             holdout_data = holdout, # holdout set\n",
    "#             treatment_column_name= \"Treated\",\n",
    "#             outcome_column_name= 'outcome123',\n",
    "#             C = 0,\n",
    "#             conn = conn,\n",
    "#             matching_option = 1,\n",
    "#             adaptive_weights = 'decisiontree',\n",
    "#             verbose = 1,\n",
    "#             missing_holdout_replace = missing_holdout_replace                \n",
    "#             )\n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
