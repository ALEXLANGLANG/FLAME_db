{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p should be larger than 2\n"
     ]
    },
    {
     "ename": "UndefinedColumn",
     "evalue": "column test_df.cov5 does not exist\nLINE 2: ...R test_df.cov3 is NULL OR test_df.cov4 is NULL OR test_df.co...\n                                                             ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUndefinedColumn\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ce7063c6405e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mholdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'treated'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m res_post_new1 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n\u001b[0m\u001b[1;32m     45\u001b[0m                         \u001b[0mholdout_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# holdout set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/github/ALex/FLAME_db/flame_db/FLAME_db_algorithm.py\u001b[0m in \u001b[0;36mFLAME_db\u001b[0;34m(input_data, holdout_data, conn, treatment_column_name, outcome_column_name, weight_array, adaptive_weights, alpha, max_depth, random_state, early_stop_iterations, early_stop_un_c_frac, early_stop_un_t_frac, early_stop_pe_frac, early_stop_pe, C, k, ratio, matching_option, verbose, missing_data_replace, missing_holdout_replace)\u001b[0m\n\u001b[1;32m    330\u001b[0m                          random_state, missing_data_replace, missing_holdout_replace) \n\u001b[1;32m    331\u001b[0m     \u001b[0mcheck_stops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mearly_stop_un_c_frac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop_un_t_frac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop_pe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop_pe_frac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     check_missings(input_data, holdout_data, conn, missing_data_replace, \n\u001b[0m\u001b[1;32m    333\u001b[0m                missing_holdout_replace, treatment_column_name, outcome_column_name) \n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/github/ALex/FLAME_db/flame_db/checker.py\u001b[0m in \u001b[0;36mcheck_missings\u001b[0;34m(db_name, df_holdout, conn, missing_data_replace, missing_holdout_replace, treatment_column_name, outcome_column_name)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmissing_data_replace\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         cur.execute(''' select count(*) from {1} \n\u001b[0m\u001b[1;32m    190\u001b[0m                         where {0}'''.format(' OR '.join([ '{1}.{0} is NULL'.format(v, db_name) for v in cov_l ]),\n\u001b[1;32m    191\u001b[0m                                                                             db_name))\n",
      "\u001b[0;31mUndefinedColumn\u001b[0m: column test_df.cov5 does not exist\nLINE 2: ...R test_df.cov3 is NULL OR test_df.cov4 is NULL OR test_df.co...\n                                                             ^\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flame_db.gen_insert_data import *\n",
    "from flame_db.FLAME_db_algorithm import *\n",
    "from flame_db.matching_helpers import *\n",
    "from flame_db.utils import *\n",
    "import unittest\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_statistics(res_post_new):\n",
    "    ATE_ = ATE_db(res_post_new)\n",
    "    ATT_ = ATT_db(res_post_new)\n",
    "    if type(ATE_) == np.nan:\n",
    "        print(\"ATE: \" + str(ATE_))\n",
    "        return True\n",
    "    if type(ATT_) == np.nan:\n",
    "        print(\"ATT:\" + str(ATT_))\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "p = 20\n",
    "TE = 5\n",
    "gen_data_db(n = 1000,p = 2, TE = TE)\n",
    "data,weight_array = gen_data_db(n = 1000,p = p, TE = TE)\n",
    "holdout,weight_array = gen_data_db(n = 500,p = p, TE = TE)\n",
    "\n",
    "#Connect to the database\n",
    "select_db = \"postgreSQL\"  # Select the database you are using\n",
    "database_name='tmp' # database name\n",
    "host = 'localhost' #host ='vcm-17819.vm.duke.edu' # \"127.0.0.1\"\n",
    "port = \"5432\"\n",
    "user=\"newuser\"\n",
    "password= \"sunxian123\"\n",
    "conn = connect_db(database_name, user, password, host, port)\n",
    "\n",
    "df = holdout.copy()\n",
    "df.loc[0,'treated'] = 4\n",
    "res_post_new1 = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "                        holdout_data = df, # holdout set\n",
    "                        C = 0.1,\n",
    "                        conn = conn,\n",
    "                        matching_option = 0,\n",
    "                        verbose = 3,\n",
    "                        k = 0\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p should be larger than 2\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "2013 (HY000): Lost connection to MySQL server at 'reading initial communication packet', system error: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMySQLInterfaceError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/mysql/connector/connection_cext.py\u001b[0m in \u001b[0;36m_open_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmysql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcnx_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMySQLInterfaceError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMySQLInterfaceError\u001b[0m: Lost connection to MySQL server at 'reading initial communication packet', system error: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ee2566bb9180>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"newuser\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"sunxian123\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnect_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"MySQL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;31m#Insert the data into database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/github/ALex/FLAME_db/flame_db/utils.py\u001b[0m in \u001b[0;36mconnect_db\u001b[0;34m(database_name, user, password, host, port, select_db, driver)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mselect_db\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"MySQL\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mmysql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         conn = mysql.connector.connect(host=host,\n\u001b[0m\u001b[1;32m     28\u001b[0m                                         \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                         \u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/mysql/connector/__init__.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mHAVE_CEXT\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_pure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCMySQLConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mMySQLConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0mConnect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnect\u001b[0m  \u001b[0;31m# pylint: disable=C0103\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/mysql/connector/connection_cext.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_default_conn_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/mysql/connector/abstracts.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;31m# Server does not allow to run any other statement different from ALTER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;31m# when user's password has been expired.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/mysql/connector/connection_cext.py\u001b[0m in \u001b[0;36m_open_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmysql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcnx_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMySQLInterfaceError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             raise errors.get_mysql_exception(msg=exc.msg, errno=exc.errno,\n\u001b[0m\u001b[1;32m    236\u001b[0m                                              sqlstate=exc.sqlstate)\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: 2013 (HY000): Lost connection to MySQL server at 'reading initial communication packet', system error: 0"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flame_db.gen_insert_data import *\n",
    "from flame_db.FLAME_db_algorithm import *\n",
    "from flame_db.matching_helpers import *\n",
    "from flame_db.utils import *\n",
    "import unittest\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_statistics(res_post_new):\n",
    "    ATE_ = ATE_db(res_post_new)\n",
    "    ATT_ = ATT_db(res_post_new)\n",
    "    if type(ATE_) == np.nan:\n",
    "        print(\"ATE: \" + str(ATE_))\n",
    "        return True\n",
    "    if type(ATT_) == np.nan:\n",
    "        print(\"ATT:\" + str(ATT_))\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "p = 20\n",
    "TE = 5\n",
    "gen_data_db(n = 100,p = 2, TE = TE)\n",
    "data,weight_array = gen_data_db(n = 1000,p = p, TE = TE)\n",
    "holdout,weight_array = gen_data_db(n = 500,p = p, TE = TE)\n",
    "# Select the database you are using\n",
    "database_name='tmp' # database name\n",
    "host ='vcm-17819.vm.duke.edu' # \"127.0.0.1\"\n",
    "port = \"5432\"\n",
    "user=\"newuser\"\n",
    "password= \"sunxian123\"\n",
    "conn = connect_db(database_name, user, password, host, port, select_db = \"MySQL\")\n",
    "#Insert the data into database\n",
    "\n",
    "insert_data_to_db(\"test_df101\", # The name of your table containing the dataset to be matched\n",
    "                    data,\n",
    "                    treatment_column_name= \"treated\",\n",
    "                    outcome_column_name= 'outcome',conn = conn)\n",
    "res_post_new1 = FLAME_db(input_data = \"test_df100\", # The name of your table containing the dataset to be matched\n",
    "                        holdout_data = holdout, # holdout set\n",
    "                        treatment_column_name= \"treated\",\n",
    "                        outcome_column_name= 'outcome',\n",
    "                        adaptive_weights = 'ridge',\n",
    "                        C = 0.1,\n",
    "                        conn = conn,\n",
    "                        matching_option = 0,\n",
    "                        verbose = 3,\n",
    "                        k = 0\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping mysql-connector-python-yes as it is not installed.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall mysql-connector-python--yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in /opt/anaconda3/lib/python3.8/site-packages (8.0.22)\n",
      "Requirement already satisfied: protobuf>=3.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from mysql-connector-python) (3.14.0)\n",
      "Requirement already satisfied: six>=1.9 in /opt/anaconda3/lib/python3.8/site-packages (from protobuf>=3.0.0->mysql-connector-python) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector in /opt/anaconda3/lib/python3.8/site-packages (2.2.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mysql-connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flame_db.gen_insert_data import *\n",
    "from flame_db.FLAME_db_algorithm import *\n",
    "from flame_db.matching_helpers import *\n",
    "from flame_db.utils import *\n",
    "import unittest\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "# #Generate toy dataset\n",
    "# p = 20\n",
    "# TE = 5\n",
    "# data,weight_array = gen_data_db(n = 5000,p = p, TE = TE)\n",
    "# holdout,weight_array = gen_data_db(n = 500,p = p, TE = TE)\n",
    "# #Connect to the database\n",
    "# select_db = \"postgreSQL\"  # Select the database you are using\n",
    "# database_name='tmp' # database name\n",
    "# host ='vcm-17819.vm.duke.edu' # \"127.0.0.1\"\n",
    "# port = \"5432\"\n",
    "# user=\"newuser\"\n",
    "# password= \"sunxian123\"\n",
    "# conn = connect_db(database_name, user, password, host, port)\n",
    "\n",
    "# #Insert the data into database\n",
    "# insert_data_to_db(\"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                     data, \n",
    "#                     treatment_column_name= \"Treated\",\n",
    "#                     outcome_column_name= 'outcome123',conn = conn)\n",
    "\n",
    "\n",
    "\n",
    "def check_statistics(res_post_new):\n",
    "    ATE_ = ATE_db(res_post_new)\n",
    "    ATT_ = ATT_db(res_post_new)\n",
    "    if type(ATE_) == np.nan:\n",
    "        print(\"ATE: \" + str(ATE_))\n",
    "        return True\n",
    "    if type(ATT_) == np.nan:\n",
    "        print(\"ATT:\" + str(ATT_))\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestFlame_db(unittest.TestCase):\n",
    "              \n",
    "    def test_weights(self):\n",
    "        is_corrct = 1\n",
    "        try:\n",
    "            for verbose in [0,1,2,3]:\n",
    "                for matching_option in [0,1,2,3]:\n",
    "                    #Test fixed weights\n",
    "                    for adaptive_weights in ['ridge', 'decisiontree',False]:\n",
    "                        res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "                                    holdout_data = holdout, # holdout set\n",
    "                                    treatment_column_name= \"Treated\",\n",
    "                                    outcome_column_name= 'outcome123',\n",
    "                                    C = 0.1,\n",
    "                                    conn = conn,\n",
    "                                    matching_option = matching_option,\n",
    "                                    adaptive_weights = adaptive_weights,\n",
    "                                    weight_array = weight_array, \n",
    "                                    verbose = verbose,\n",
    "                                    k = 0\n",
    "                                    )\n",
    "                        if check_statistics(res_post_new):\n",
    "                            is_corrct = 0\n",
    "            \n",
    "        except (KeyError, ValueError):\n",
    "                is_corrct = 0\n",
    "\n",
    "        self.assertEqual(1, is_corrct,\n",
    "                             msg='Error when test weights')        \n",
    "            \n",
    "    def test_stop_iterations(self):\n",
    "        is_corrct = 1\n",
    "        try:\n",
    "            for early_stop_iterations in [2,3]:\n",
    "                res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "                            holdout_data = holdout, # holdout set\n",
    "                            treatment_column_name= \"Treated\",\n",
    "                            outcome_column_name= 'outcome123',\n",
    "                            C = 0.1,\n",
    "                            conn = conn,\n",
    "                            matching_option = 0,\n",
    "                            adaptive_weights = 'decisiontree',\n",
    "                            verbose = 1,\n",
    "                            k = 0,\n",
    "                            early_stop_iterations = early_stop_iterations            \n",
    "                            )\n",
    "                if check_statistics(res_post_new):\n",
    "                    is_corrct = 0\n",
    "            \n",
    "        except (KeyError, ValueError):\n",
    "                is_corrct = 0\n",
    "\n",
    "        self.assertEqual(1, is_corrct,\n",
    "                             msg='Error when test stop_iterations')        \n",
    "\n",
    "    def test_missing_datasets(self):\n",
    "            is_corrct = 1\n",
    "            try:    \n",
    "                for missing_data_replace in [0,1,2]:\n",
    "                    for missing_holdout_replace in [0,1]:  \n",
    "                        holdout_miss = holdout.copy()\n",
    "                        m,n = holdout_miss.shape\n",
    "                        for i in range(int(m/100)):\n",
    "                            for j in [0,int(n/2)]:\n",
    "                                holdout_miss.iloc[i,j] = np.nan\n",
    "                        res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "                                                holdout_data = holdout_miss, # holdout set\n",
    "                                                treatment_column_name= \"Treated\",\n",
    "                                                outcome_column_name= 'outcome123',\n",
    "                                                C = 0,\n",
    "                                                conn = conn,\n",
    "                                                matching_option = 1,\n",
    "                                                adaptive_weights = 'decisiontree',\n",
    "                                                verbose = 1,\n",
    "                                                missing_data_replace = missing_data_replace,\n",
    "                                                missing_holdout_replace = missing_holdout_replace) \n",
    "                        if check_statistics(res_post_new):\n",
    "                            is_corrct = 0\n",
    "\n",
    "            except (KeyError, ValueError):\n",
    "                    is_corrct = 0\n",
    "\n",
    "            self.assertEqual(1, is_corrct,\n",
    "                                 msg='Error when test missing datasets')  \n",
    "\n",
    "        #     print(ATE_db(res_post_new))\n",
    "        #     print(ATT_db(res_post_new))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TestFlame_db()\n",
    "t.test_missing_datasets()\n",
    "t.test_stop_iterations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert 5000 rows successfully to Database\n",
      "un_matched in total:  4980\n",
      "matched in total:  20\n",
      "Level1: Do matching without dropping any covs\n",
      "Level2: No matching after fast drop cov19 with adaptive score: (PE: 2.1515979204152424 BF: 0.0032129389827080333)\n",
      "Level3: No matching after fast drop cov11 with adaptive score: (PE: 2.1408287977573073 BF: 0.008032347456770082)\n",
      "Level4: No matching after fast drop cov13 with adaptive score: (PE: 2.1336085972618095 BF: 0.0289164508443723)\n",
      "Level5: No matching after fast drop cov20 with adaptive score: (PE: 2.1274093261597695 BF: 0.07269484128129813)\n",
      "Level6: No matching after fast drop cov18 with adaptive score: (PE: 2.1196818334913257 BF: 0.15100813218727757)\n",
      "Level7: No matching after fast drop cov14 with adaptive score: (PE: 2.112468241452367 BF: 0.2887440198931246)\n",
      "Level8: No matching after fast drop cov15 with adaptive score: (PE: 2.107741228608934 BF: 0.5365398421369528)\n",
      "Level9: No matching after fast drop cov16 with adaptive score: (PE: 2.1086304337524995 BF: 0.9229628523285178)\n",
      "Level10: No matching after fast drop cov17 with adaptive score: (PE: 2.1092224766833088 BF: 1.4161951157198363)\n",
      "un_matched in total:  1454\n",
      "matched in total:  3546\n",
      "Found the boundary to switch to slowly dropping important covariates.\n",
      "Level11: Do matching after slow drop cov12 with adaptive score: (PE: 2.135452603700416 BF: 0.4308065176823995)\n",
      "un_matched in total:  1141\n",
      "matched in total:  3859\n",
      "Early stopping: predictive error would have risen  25.0 % above the baseline.\n",
      "Done matching:\n",
      "\tNumber of units matched so far:  3859\n",
      "\tNumber of covariates dropped in total:  11\n",
      "\tNumber of matched groups formed in total:  1108\n",
      "\tUnmatched treated units:  541 out of a total of  2487 treated units\n",
      "\tUnmatched control units:  600 out of a total of  2513 control units\n"
     ]
    }
   ],
   "source": [
    "p = 20\n",
    "TE = 5\n",
    "data,weight_array = gen_data_db(n = 5000,p = p, TE = TE)\n",
    "holdout,weight_array = gen_data_db(n = 500,p = p, TE = TE)\n",
    "holdout = pd.read_csv(\"holdout.csv\")\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "#Connect to the database\n",
    "select_db = \"postgreSQL\"  # Select the database you are using\n",
    "database_name='tmp' # database name\n",
    "host ='vcm-17819.vm.duke.edu' # \"127.0.0.1\"\n",
    "port = \"5432\"\n",
    "user=\"newuser\"\n",
    "password= \"sunxian123\"\n",
    "conn = connect_db(database_name, user, password, host, port)\n",
    "\n",
    "#Insert the data into database\n",
    "insert_data_to_db(\"test_df\", # The name of your table containing the dataset to be matched\n",
    "                    data, \n",
    "                    treatment_column_name= \"Treated\",\n",
    "                    outcome_column_name= 'outcome123',conn = conn)\n",
    "for verbose in [2]:\n",
    "    for matching_option in [0]:\n",
    "        #Test fixed weights\n",
    "        for adaptive_weights in ['ridge']:\n",
    "            res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "                        holdout_data = holdout, # holdout set\n",
    "                        treatment_column_name= \"Treated\",\n",
    "                        outcome_column_name= 'outcome123',\n",
    "                        C = 0.1,\n",
    "                        conn = conn,\n",
    "                        matching_option = matching_option,\n",
    "                        adaptive_weights = adaptive_weights,\n",
    "                        weight_array = weight_array, \n",
    "                        verbose = verbose,\n",
    "                        k = 0\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_post_new[0][0]['num_control'].sum() + res_post_new[0][0]['num_treated'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3526"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_post_new[0][1]['num_control'].sum() + res_post_new[0][1]['num_treated'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_post_new[0][2]['num_control'].sum() + res_post_new[0][2]['num_treated'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#             holdout_data = holdout, # holdout set\n",
    "#             treatment_column_name= \"Treated\",\n",
    "#             outcome_column_name= 'outcome123',\n",
    "#             C = 0.1,\n",
    "#             conn = conn,\n",
    "#             matching_option = 0,\n",
    "#             adaptive_weights = 'ridge',\n",
    "#             weight_array = weight_array, \n",
    "#             verbose = 2,\n",
    "#             k = 0\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cov1</th>\n",
       "      <th>cov2</th>\n",
       "      <th>cov3</th>\n",
       "      <th>cov4</th>\n",
       "      <th>cov5</th>\n",
       "      <th>cov6</th>\n",
       "      <th>cov7</th>\n",
       "      <th>cov8</th>\n",
       "      <th>cov9</th>\n",
       "      <th>cov10</th>\n",
       "      <th>...</th>\n",
       "      <th>cov13</th>\n",
       "      <th>cov14</th>\n",
       "      <th>cov15</th>\n",
       "      <th>cov16</th>\n",
       "      <th>cov17</th>\n",
       "      <th>cov18</th>\n",
       "      <th>cov19</th>\n",
       "      <th>cov20</th>\n",
       "      <th>Treated</th>\n",
       "      <th>outcome123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.256918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>203.979121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.233244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>169.724566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>184.322700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>159.231762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.831038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>186.366591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>136.735527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.017359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cov1  cov2  cov3  cov4  cov5  cov6  cov7  cov8  cov9 cov10  ... cov13  \\\n",
       "0    Good   Bad  Good   Bad   Bad  Good  Good   Bad   Bad   Bad  ...   Bad   \n",
       "1    Good  Good  Good   Bad  Good  Good  Good  Good  Good   Bad  ...   Bad   \n",
       "2    Good   Bad  Good   Bad   Bad  Good   Bad  Good   Bad   Bad  ...  Good   \n",
       "3     Bad  Good  Good   Bad  Good  Good   Bad  Good  Good   Bad  ...   Bad   \n",
       "4    Good  Good   Bad  Good  Good   Bad  Good  Good  Good   Bad  ...   Bad   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "495  Good   Bad   Bad  Good  Good  Good  Good  Good   Bad   Bad  ...   Bad   \n",
       "496   Bad   Bad   Bad   Bad   Bad  Good   Bad   Bad  Good  Good  ...   Bad   \n",
       "497   Bad  Good  Good   Bad  Good   Bad  Good   Bad  Good  Good  ...   Bad   \n",
       "498  Good  Good   Bad   Bad   Bad  Good   Bad  Good  Good   Bad  ...  Good   \n",
       "499   Bad   Bad   Bad   Bad   Bad  Good   Bad   Bad   Bad   Bad  ...  Good   \n",
       "\n",
       "    cov14 cov15 cov16 cov17 cov18 cov19 cov20 Treated  outcome123  \n",
       "0     Bad  Good  Good   Bad   Bad   Bad   1.0     1.0   89.256918  \n",
       "1    Good   Bad  Good   Bad  Good   Bad   1.0     0.0  203.979121  \n",
       "2    Good   Bad  Good  Good  Good  Good   0.0     1.0   94.233244  \n",
       "3    Good   Bad  Good   Bad   Bad   Bad   1.0     1.0  169.724566  \n",
       "4     Bad   Bad   Bad  Good  Good   Bad   1.0     1.0  184.322700  \n",
       "..    ...   ...   ...   ...   ...   ...   ...     ...         ...  \n",
       "495  Good  Good   Bad  Good  Good   Bad   0.0     1.0  159.231762  \n",
       "496  Good  Good   Bad  Good   Bad   Bad   0.0     0.0  124.831038  \n",
       "497   Bad  Good   Bad  Good  Good   Bad   0.0     1.0  186.366591  \n",
       "498   Bad   Bad   Bad   Bad  Good   Bad   1.0     1.0  136.735527  \n",
       "499   Bad   Bad  Good   Bad   Bad  Good   0.0     1.0   36.017359  \n",
       "\n",
       "[500 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout.to_csv(\"holdout.csv\",index = None)\n",
    "data.to_csv(\"data.csv\",index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# t = TestFlame_db()\n",
    "# t.test_weights()\n",
    "# t.test_stop_iterations()\n",
    "# t.test_missing_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# #**********************************Test**********************************#\n",
    "\n",
    "\n",
    "    \n",
    "# for C in [0.0, 0.2,0.6]:\n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                     holdout_data = holdout, # holdout set\n",
    "#                     treatment_column_name= \"Treated\",\n",
    "#                     outcome_column_name= 'outcome123',\n",
    "#                     C = C,\n",
    "#                     conn = conn,\n",
    "#                     matching_option = 1,\n",
    "#                     adaptive_weights = 'ridge',\n",
    "#                     verbose = verbose,\n",
    "#                     k = 0\n",
    "#                     )\n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "# for matching_option in [0,1,2,3]: \n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                     holdout_data = holdout, # holdout set\n",
    "#                     treatment_column_name= \"Treated\",\n",
    "#                     outcome_column_name= 'outcome123',\n",
    "#                     C = 0.0,\n",
    "#                     conn = conn,\n",
    "#                     matching_option = matching_option,\n",
    "#                     adaptive_weights = 'ridge',\n",
    "#                     verbose = 1,\n",
    "#                     k = 0\n",
    "#                     )\n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "\n",
    "\n",
    "# for alpha in [0.1,0.8]:\n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                 holdout_data = holdout, # holdout set\n",
    "#                 treatment_column_name= \"Treated\",\n",
    "#                 outcome_column_name= 'outcome123',\n",
    "#                 C = 0,\n",
    "#                 conn = conn,\n",
    "#                 matching_option = 1,\n",
    "#                 adaptive_weights = 'decisiontree',\n",
    "#                 verbose = 1,\n",
    "#                 k = 0,\n",
    "#                 alpha = alpha,\n",
    "#                 early_stop_iterations = 2            \n",
    "#                 )\n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "# for max_depth in [8,9]:\n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                 holdout_data = holdout, # holdout set\n",
    "#                 treatment_column_name= \"Treated\",\n",
    "#                 outcome_column_name= 'outcome123',\n",
    "#                 C = 0,\n",
    "#                 conn = conn,\n",
    "#                 matching_option = 1,\n",
    "#                 adaptive_weights = 'decisiontree',\n",
    "#                 verbose = 1,\n",
    "#                 k = 0,\n",
    "#                 max_depth = max_depth,\n",
    "#                 early_stop_iterations = 2            \n",
    "#                 )\n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "    \n",
    "\n",
    "# for k in [0,2,4]:\n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                 holdout_data = holdout, # holdout set\n",
    "#                 treatment_column_name= \"Treated\",\n",
    "#                 outcome_column_name= 'outcome123',\n",
    "#                 C = 0,\n",
    "#                 conn = conn,\n",
    "#                 matching_option = 1,\n",
    "#                 adaptive_weights = 'decisiontree',\n",
    "#                 verbose = 1,\n",
    "#                 k = k\n",
    "#                 )\n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "# for ratio in [0.01,0.1]:\n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#                 holdout_data = holdout, # holdout set\n",
    "#                 treatment_column_name= \"Treated\",\n",
    "#                 outcome_column_name= 'outcome123',\n",
    "#                 C = 0,\n",
    "#                 conn = conn,\n",
    "#                 matching_option = 1,\n",
    "#                 adaptive_weights = 'decisiontree',\n",
    "#                 verbose = 1,\n",
    "#                 ratio = ratio\n",
    "#                 )\n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "# for early_stop_un_c_frac in [0.2,0.5]:\n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#             holdout_data = holdout, # holdout set\n",
    "#             treatment_column_name= \"Treated\",\n",
    "#             outcome_column_name= 'outcome123',\n",
    "#             C = 0,\n",
    "#             conn = conn,\n",
    "#             matching_option = 1,\n",
    "#             adaptive_weights = 'decisiontree',\n",
    "#             verbose = 1,\n",
    "#             early_stop_un_c_frac = early_stop_un_c_frac                \n",
    "#             )\n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "    \n",
    "# for early_stop_un_t_frac in [0.2,0.5]:\n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#             holdout_data = holdout, # holdout set\n",
    "#             treatment_column_name= \"Treated\",\n",
    "#             outcome_column_name= 'outcome123',\n",
    "#             C = 0,\n",
    "#             conn = conn,\n",
    "#             matching_option = 1,\n",
    "#             adaptive_weights = 'decisiontree',\n",
    "#             verbose = 1,\n",
    "#             early_stop_un_t_frac = early_stop_un_t_frac                \n",
    "#             )\n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "# for early_stop_pe in [3,5]:\n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#             holdout_data = holdout, # holdout set\n",
    "#             treatment_column_name= \"Treated\",\n",
    "#             outcome_column_name= 'outcome123',\n",
    "#             C = 0,\n",
    "#             conn = conn,\n",
    "#             matching_option = 1,\n",
    "#             adaptive_weights = 'decisiontree',\n",
    "#             verbose = 1,\n",
    "#             early_stop_pe = early_stop_pe                \n",
    "#             )\n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "# for early_stop_pe_frac in [0.5,1]:    \n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#             holdout_data = holdout, # holdout set\n",
    "#             treatment_column_name= \"Treated\",\n",
    "#             outcome_column_name= 'outcome123',\n",
    "#             C = 0,\n",
    "#             conn = conn,\n",
    "#             matching_option = 1,\n",
    "#             adaptive_weights = 'decisiontree',\n",
    "#             verbose = 1,\n",
    "#             early_stop_pe_frac = early_stop_pe_frac                \n",
    "#             )   \n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "# for missing_data_replace in [0,1,2]:\n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#             holdout_data = holdout, # holdout set\n",
    "#             treatment_column_name= \"Treated\",\n",
    "#             outcome_column_name= 'outcome123',\n",
    "#             C = 0,\n",
    "#             conn = conn,\n",
    "#             matching_option = 1,\n",
    "#             adaptive_weights = 'decisiontree',\n",
    "#             verbose = 1,\n",
    "#             missing_data_replace = missing_data_replace                \n",
    "#             ) \n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n",
    "# for missing_holdout_replace in [0,1]:    \n",
    "#     res_post_new = FLAME_db(input_data = \"test_df\", # The name of your table containing the dataset to be matched\n",
    "#             holdout_data = holdout, # holdout set\n",
    "#             treatment_column_name= \"Treated\",\n",
    "#             outcome_column_name= 'outcome123',\n",
    "#             C = 0,\n",
    "#             conn = conn,\n",
    "#             matching_option = 1,\n",
    "#             adaptive_weights = 'decisiontree',\n",
    "#             verbose = 1,\n",
    "#             missing_holdout_replace = missing_holdout_replace                \n",
    "#             )\n",
    "#     print(ATE_db(res_post_new))\n",
    "#     print(ATT_db(res_post_new))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_exceptions(unittest.TestCase):\n",
    "    \n",
    "    def test_false_dataset(self):\n",
    "        def broken_false_dataset():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=1000, num_treated=1000)\n",
    "            holdout, true_TE = generate_uniform_given_importance(num_control=1000, num_treated=1000)\n",
    "            model = matching.FLAME()\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(False)\n",
    "\n",
    "            \n",
    "        with self.assertRaises(Exception) as false_dataset:\n",
    "            broken_false_dataset()\n",
    "            \n",
    "        self.assertTrue(\"Need to specify either csv file name or pandas data \"\\\n",
    "                        \"frame in parameter 'input_data'\" in str(false_dataset.exception))\n",
    "        \n",
    "    def test_false_early_stop_un_t_frac(self):\n",
    "        def broken_early_stop_un_t_frac():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            model = matching.FLAME(early_stop_un_t_frac = -1)\n",
    "            model.fit(holdout_data=df)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as early_stop_un_t_frac:\n",
    "            broken_early_stop_un_t_frac()\n",
    "            \n",
    "        self.assertTrue('The value provided for the early stopping critera '\\\n",
    "                        'of proportion of unmatched treatment units needs to '\\\n",
    "                        'be between 0.0 and 1.0' in str(early_stop_un_t_frac.exception))\n",
    "    \n",
    "    def test_false_early_stop_un_c_frac(self):\n",
    "        def broken_early_stop_un_c_frac():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            model = matching.FLAME(early_stop_un_c_frac = -1)\n",
    "            model.fit(holdout_data=df)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as early_stop_un_c_frac:\n",
    "            broken_early_stop_un_c_frac()\n",
    "            \n",
    "        self.assertTrue('The value provided for the early stopping critera '\\\n",
    "                        'of proportion of unmatched control units needs to '\\\n",
    "                        'be between 0.0 and 1.0' in str(early_stop_un_c_frac.exception))\n",
    "        \n",
    "        \n",
    "    def test_false_early_stop_iterations(self):\n",
    "        def broken_early_stop_iterations():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            model = matching.FLAME(early_stop_iterations = True)\n",
    "            model.fit(holdout_data=df)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as early_stop_iterations:\n",
    "            broken_early_stop_iterations()\n",
    "            \n",
    "        self.assertTrue('The value provided for early_stop_iteration needs '\\\n",
    "                        'to be an integer number of iterations, or False if '\\\n",
    "                        'not stopping early based on the number of iterations' in str(early_stop_iterations.exception))\n",
    "    def test_false_early_stop_pe_frac(self):\n",
    "        def broken_early_stop_pe_frac():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            model = matching.FLAME(early_stop_pe_frac = 123)\n",
    "            model.fit(holdout_data=df)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as early_stop_pe_frac:\n",
    "            broken_early_stop_pe_frac()\n",
    "            \n",
    "        self.assertTrue('The value provided for the early stopping critera of'\\\n",
    "                        ' PE needs to be between 0.0 and 1.0' in str(early_stop_pe_frac.exception))\n",
    "\n",
    "\n",
    "    def test_false_weight_array_type(self):\n",
    "        def broken_weight_array_type():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            model = matching.FLAME(adaptive_weights = False)\n",
    "            model.fit(holdout_data=df, weight_array = np.array([1,2,3,4,5]))\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as weight_array_type:\n",
    "            broken_weight_array_type()\n",
    "            \n",
    "        self.assertTrue('Invalid input error. A weight array of type'\\\n",
    "                            'array needs to be provided when the'\\\n",
    "                            'parameter adaptive_weights == True' in str(weight_array_type.exception))\n",
    "\n",
    "    def test_false_weight_array_len(self):\n",
    "        def broken_weight_array_len():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            model = matching.FLAME(adaptive_weights = False)\n",
    "            model.fit(holdout_data=df, weight_array = [1])\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as weight_array_len:\n",
    "            broken_weight_array_len()\n",
    "            \n",
    "        self.assertTrue('Invalid input error. Weight array size not equal'\\\n",
    "                            ' to number of columns in dataframe' in str(weight_array_len.exception))\n",
    "        \n",
    "        \n",
    "    def test_false_weight_array_sum(self):\n",
    "        def broken_weight_array_sum():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            model = matching.FLAME(adaptive_weights = False)\n",
    "            model.fit(holdout_data=df, weight_array = [1,1,1,1])\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as weight_array_sum:\n",
    "            broken_weight_array_sum()\n",
    "            \n",
    "        self.assertTrue('Invalid input error. Weight array values must '\\\n",
    "                            'sum to 1.0' in str(weight_array_sum.exception))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def test_false_alpha(self):\n",
    "        def broken_alpha():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            model = matching.FLAME(adaptive_weights = 'ridge',alpha = -10)\n",
    "            model.fit(holdout_data=df)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as alpha:\n",
    "            broken_alpha()\n",
    "            \n",
    "        self.assertTrue('Invalid input error. The alpha needs to be '\\\n",
    "                            'positive for ridge regressions.' in str(alpha.exception))\n",
    "        \n",
    "    def test_false_adaptive_weights(self):\n",
    "        def broken_adaptive_weights():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            model = matching.FLAME(adaptive_weights = 'safdsaf')\n",
    "            model.fit(holdout_data=df)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as adaptive_weights:\n",
    "            broken_adaptive_weights()\n",
    "            \n",
    "        self.assertTrue(\"Invalid input error. The acceptable values for \"\\\n",
    "                            \"the adaptive_weights parameter are 'ridge', \"\\\n",
    "                            \"'decisiontree', 'decisiontreeCV', or 'ridgeCV'. Additionally, \"\\\n",
    "                            \"adaptive-weights may be 'False' along \"\\\n",
    "                            \"with a weight array\" in str(adaptive_weights.exception))\n",
    "        \n",
    "    def test_false_data_len(self):\n",
    "        def broken_data_len():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=1000, num_treated=1000,\n",
    "                                                  num_cov=7, min_val=0,\n",
    "                                                  max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "            holdout, true_TE = generate_uniform_given_importance()\n",
    "            model = matching.FLAME()\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as data_len:\n",
    "            broken_data_len()\n",
    "            \n",
    "        self.assertTrue('Invalid input error. The holdout and main '\\\n",
    "                            'dataset must have the same number of columns' in str(data_len.exception))\n",
    "    \n",
    "    def test_false_column_match(self):\n",
    "        def broken_column_match():\n",
    "            df, true_TE = generate_uniform_given_importance()\n",
    "            holdout, true_TE = generate_uniform_given_importance()\n",
    "            set_ = holdout.columns\n",
    "            set_ = list(set_)\n",
    "            set_[0] = 'dasfadf'\n",
    "            holdout.columns  = set_\n",
    "            model = matching.FLAME()\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as column_match:\n",
    "            broken_column_match()\n",
    "            \n",
    "        self.assertTrue('Invalid input error. The holdout and main '\\\n",
    "                            'dataset must have the same columns' in str(column_match.exception))\n",
    "    def test_false_C(self):\n",
    "        def broken_C():\n",
    "            df, true_TE = generate_uniform_given_importance()\n",
    "            holdout, true_TE = generate_uniform_given_importance()\n",
    "\n",
    "            model = matching.FLAME()\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df,C = -1)\n",
    "\n",
    "        with self.assertRaises(Exception) as C:\n",
    "            broken_C()\n",
    "            \n",
    "        self.assertTrue('The C, or the hyperparameter to trade-off between'\\\n",
    "                           ' balancing factor and predictive error must be '\\\n",
    "                           ' nonnegative. 'in str(C.exception))\n",
    "    def test_false_missing_data_replace(self):\n",
    "        def broken_missing_data_replace():\n",
    "                df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100,\n",
    "                                                              num_cov=7, min_val=0,\n",
    "                                                              max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "                holdout, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100,\n",
    "                                                      num_cov=7, min_val=0,\n",
    "                                                          max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "                covar_importance = np.array([4,3,2,1,0,0,0])\n",
    "                weight_array = covar_importance/covar_importance.sum()\n",
    "                model = matching.FLAME(missing_data_replace = 2, adaptive_weights =False)\n",
    "                model.fit(holdout_data=holdout,weight_array = list(weight_array))\n",
    "                output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as missing_data_replace:\n",
    "            broken_missing_data_replace()\n",
    "            \n",
    "        self.assertTrue('Invalid input error. We do not support missing data '\\\n",
    "                        'handing in the fixed weights version of algorithms'in str(missing_data_replace.exception))\n",
    "        \n",
    "    def test_false_treatment_column_name(self):\n",
    "        def broken_treatment_column_name():\n",
    "            df, true_TE = generate_uniform_given_importance()\n",
    "            holdout, true_TE = generate_uniform_given_importance()\n",
    "            model = matching.FLAME()\n",
    "            model.fit(holdout_data=holdout,treatment_column_name =  \"sadfdag\")\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as treatment_column_name:\n",
    "            broken_treatment_column_name()\n",
    "            \n",
    "        self.assertTrue('Invalid input error. Treatment column name does not'\\\n",
    "                        ' exist' in str(treatment_column_name.exception))\n",
    "\n",
    "    def test_false_outcome_column_name(self):\n",
    "        def broken_outcome_column_name():\n",
    "            df, true_TE = generate_uniform_given_importance()\n",
    "            holdout, true_TE = generate_uniform_given_importance()\n",
    "            model = matching.FLAME()\n",
    "            model.fit(holdout_data=holdout,outcome_column_name =  \"sadfdag\")\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as outcome_column_name:\n",
    "            broken_outcome_column_name()\n",
    "            \n",
    "        self.assertTrue('Invalid input error. Outcome column name does not'\\\n",
    "                        ' exist' in str(outcome_column_name.exception))\n",
    "        \n",
    "    def test_false_treatment_column_name_value(self):\n",
    "        def broken_treatment_column_name_value():\n",
    "            df, true_TE = generate_uniform_given_importance()\n",
    "            holdout, true_TE = generate_uniform_given_importance()\n",
    "            df.loc[0,'treated'] = 4\n",
    "            model = matching.FLAME()\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as treatment_column_name_value:\n",
    "            broken_treatment_column_name_value()\n",
    "        self.assertTrue('Invalid input error. All rows in the treatment '\\\n",
    "                        'column must have either a 0 or a 1 value.' in str(treatment_column_name_value.exception))\n",
    "        \n",
    "\n",
    "        \n",
    "    def test_false_data_type(self):\n",
    "        def broken_data_type():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            holdout = df.copy()\n",
    "            df.iloc[0,0] = 's'\n",
    "            model = matching.FLAME()\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as _data_type:\n",
    "            broken_data_type()\n",
    "\n",
    "        self.assertTrue('Invalid input error on matching dataset. Ensure all inputs asides from '\\\n",
    "                        'the outcome column are integers, and if missing' \\\n",
    "                        ' values exist, ensure they are handled.' in str(_data_type.exception))\n",
    "    def test_false_holdout_type(self):\n",
    "        def broken_holdout_type():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            holdout = df.copy()\n",
    "            holdout.iloc[0,0] = 's'\n",
    "            model = matching.FLAME()\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as holdout_type:\n",
    "            broken_holdout_type()\n",
    "\n",
    "        self.assertTrue('Invalid input error on holdout dataset. Ensure all inputs asides from '\\\n",
    "                                'the outcome column are integers, and if missing' \\\n",
    "                                ' values exist, ensure they are handled.' in str(holdout_type.exception))\n",
    "\n",
    "    def test_false_ATE_input(self):\n",
    "        def broken_ATE_input():\n",
    "            ATE(1)\n",
    "\n",
    "        with self.assertRaises(Exception) as ATE_input:\n",
    "            broken_ATE_input()\n",
    "        self.assertTrue(\"The matching_object input parameter needs to be \"\\\n",
    "                            \"of type DAME or FLAME\" in str(ATE_input.exception))\n",
    "\n",
    "    def test_false_ATE_input_model(self):\n",
    "        def broken_ATE_input_model():\n",
    "            model = matching.FLAME()\n",
    "            ATE(model)\n",
    "        with self.assertRaises(Exception) as ATE_input_model:\n",
    "            broken_ATE_input_model()\n",
    "        self.assertTrue(\"This function can be only called after a match has \"\\\n",
    "                           \"been formed using the .fit() and .predict() functions\" in str(ATE_input_model.exception))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
